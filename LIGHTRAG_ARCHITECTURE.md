# LightRAG 架构详解

> 本文档面向完全不了解 LightRAG 的读者，从零开始介绍其核心概念、架构设计和工作流程。

## 目录

- [1. 什么是 LightRAG](#1-什么是-lightrag)
- [2. 核心概念](#2-核心概念)
- [3. 总体架构](#3-总体架构)
- [4. 数据导入流程](#4-数据导入流程)
- [5. 查询检索流程](#5-查询检索流程)
- [6. 存储架构](#6-存储架构)
- [7. 配置参数详解](#7-配置参数详解)
- [8. 实际示例](#8-实际示例)

---

## 1. 什么是 LightRAG

### 1.1 RAG 简介

**RAG (Retrieval-Augmented Generation)** 是一种结合检索和生成的 AI 技术：

```
传统 LLM：用户提问 → LLM 直接回答（可能产生幻觉）

RAG：用户提问 → 检索相关文档 → 将文档作为上下文 → LLM 基于文档回答
```

### 1.2 LightRAG 的特点

LightRAG 是一个**轻量级的图增强 RAG 框架**，核心创新：

| 特性   | 传统 RAG | LightRAG      |
|------|--------|---------------|
| 检索方式 | 纯向量相似度 | 向量 + 知识图谱     |
| 知识表示 | 文档块    | 文档块 + 实体 + 关系 |
| 关联发现 | 弱      | 强（图遍历）        |

**一句话总结**：LightRAG = 向量检索 + 知识图谱，两者优势互补。

---

## 2. 核心概念

### 2.1 文档块 (Chunk)

将长文档切分成小块，便于处理和检索。

```
原始文档（10000字）
    ↓ 按 1200 tokens 切分
┌─────────┬─────────┬─────────┬─────────┐
│ Chunk 1 │ Chunk 2 │ Chunk 3 │ Chunk 4 │
└─────────┴─────────┴─────────┴─────────┘
```

**参数**：

- `chunk_token_size`: 每块大小（默认 1200 tokens）
- `chunk_overlap_token_size`: 块之间重叠大小（默认 100 tokens）

### 2.2 实体 (Entity)

从文本中提取的**关键概念**，如人名、地名、专业术语等。

```
文本："华为公司2023年营收达到7000亿元"

提取的实体：
- 华为公司（组织）
- 2023年（时间）
- 7000亿元（金额）
- 营收（概念）
```

### 2.3 关系 (Relation)

实体之间的**语义连接**。

```
实体：华为公司、营收、7000亿元

关系：
- (华为公司) --[拥有]--> (营收)
- (营收) --[金额为]--> (7000亿元)
```

### 2.4 知识图谱 (Knowledge Graph)

由实体和关系构成的**网络结构**。

```
        ┌─────────┐
        │ 华为公司 │
        └────┬────┘
             │拥有
        ┌────▼────┐
        │   营收   │
        └────┬────┘
             │金额为
        ┌────▼────┐
        │ 7000亿元 │
        └─────────┘
```

### 2.5 向量 (Embedding)

将文本转换为**数值向量**，用于计算语义相似度。

```
"华为公司" → [0.12, -0.34, 0.56, ..., 0.78]  (1024维向量)
"腾讯公司" → [0.11, -0.33, 0.55, ..., 0.77]  (相似)
"苹果水果" → [0.89, 0.12, -0.45, ..., 0.23]  (不相似)
```

---

## 3. 总体架构

### 3.1 架构图

```
┌─────────────────────────────────────────────────────────────────┐
│                         LightRAG                                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  ┌──────────────┐    ┌──────────────┐    ┌──────────────┐       │
│  │   文档输入    │ → │   处理引擎    │ → │   存储层     │       │
│  └──────────────┘    └──────────────┘    └──────────────┘       │
│         │                   │                   │                │
│         ▼                   ▼                   ▼                │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │                      存储组件                            │    │
│  │  ┌─────────┐  ┌─────────┐  ┌─────────┐  ┌─────────┐    │    │
│  │  │ VectorDB│  │  Neo4j  │  │KV Store │  │Doc Store│    │    │
│  │  │(向量库) │  │(图数据库)│  │(键值库) │  │(文档状态)│    │    │
│  │  └─────────┘  └─────────┘  └─────────┘  └─────────┘    │    │
│  └─────────────────────────────────────────────────────────┘    │
│                                                                  │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │                      外部服务                             │   │
│  │  ┌─────────────────┐    ┌─────────────────┐              │   │
│  │  │    LLM API      │    │  Embedding API  │              │   │
│  │  │ (实体提取/问答)  │    │   (向量化)      │              │   │
│  │  └─────────────────┘    └─────────────────┘              │   │
│  └──────────────────────────────────────────────────────────┘   │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### 3.2 组件说明

| 组件                | 作用           | 示例实现                 |
|-------------------|--------------|----------------------|
| **VectorDB**      | 存储向量，支持相似度检索 | NanoVectorDB, Faiss  |
| **Neo4j**         | 存储知识图谱，支持图遍历 | Neo4j Aura           |
| **KV Store**      | 存储实体/关系的详细描述 | JsonKVStorage        |
| **Doc Store**     | 存储文档处理状态     | JsonDocStatusStorage |
| **LLM API**       | 提取实体关系、生成回答  | OpenAI, Gemini       |
| **Embedding API** | 文本向量化        | OpenAI, SiliconFlow  |

---

## 4. 数据导入流程

### 4.1 流程图

```
┌─────────────────────────────────────────────────────────────────┐
│                      数据导入流程                                │
└─────────────────────────────────────────────────────────────────┘

     ┌─────────┐
     │ 原始文档 │
     └────┬────┘
          │
          ▼
┌─────────────────┐
│  Step 1: 分块   │  将文档切分为多个 Chunks
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  Step 2: 提取   │  LLM 从每个 Chunk 提取实体和关系
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  Step 3: 合并   │  合并同名实体的描述（去重）
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  Step 4: 向量化 │  对 Chunks/实体/关系描述生成向量
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  Step 5: 入库   │  向量→VectorDB，图→Neo4j，描述→KV
└─────────────────┘
```

### 4.2 详细步骤

#### Step 1: 文档分块

```python
# 输入
document = "华为公司2023年营收达到7000亿元，同比增长10%。其中消费者业务贡献了2500亿元..."

# 输出（假设 chunk_size=50）
chunks = [
    "华为公司2023年营收达到7000亿元，同比增长10%。",
    "其中消费者业务贡献了2500亿元..."
]
```

#### Step 2: LLM 提取实体和关系

```python
# 对每个 Chunk 调用 LLM
chunk = "华为公司2023年营收达到7000亿元，同比增长10%。"

# LLM 返回（JSON格式）
{
    "entities": [
        {"name": "华为公司", "type": "组织", "description": "中国领先的科技公司"},
        {"name": "营收", "type": "财务指标", "description": "公司的总收入"},
        {"name": "7000亿元", "type": "金额", "description": "2023年华为营收数额"}
    ],
    "relations": [
        {"source": "华为公司", "target": "营收", "description": "华为公司拥有营收指标"},
        {"source": "营收", "target": "7000亿元", "description": "2023年营收金额为7000亿元"}
    ]
}
```

#### Step 3: 实体合并

当同一实体在多个 Chunk 中出现时，合并其描述：

```python
# Chunk 1 提取
{"name": "华为公司", "description": "中国领先的科技公司"}

# Chunk 2 提取
{"name": "华为公司", "description": "全球通信设备龙头企业"}

# 合并后
{"name": "华为公司", "description": "中国领先的科技公司。全球通信设备龙头企业。"}

# 日志显示：Merged: `华为公司` | 1+1
```

#### Step 4: 向量化

```python
# 需要向量化的内容
to_embed = [
    # Chunks
    "华为公司2023年营收达到7000亿元...",

    # 实体描述
    "华为公司：中国领先的科技公司。全球通信设备龙头企业。",
    "营收：公司的总收入...",

    # 关系描述
    "华为公司拥有营收指标...",
]

# 调用 Embedding API
vectors = embedding_api.embed(to_embed)  # 返回向量列表
```

#### Step 5: 存储入库

```python
# 1. 向量存入 VectorDB
vector_db.upsert(id="华为公司", vector=[0.12, -0.34, ...])

# 2. 图关系存入 Neo4j
neo4j.merge_node(name="华为公司", type="组织")
neo4j.merge_edge(source="华为公司", target="营收", relation="拥有")

# 3. 详细描述存入 KV Store
kv_store.set("华为公司", {"description": "中国领先的科技公司...", "chunks": [...]})
```

---

## 5. 查询检索流程

### 5.1 流程图

```
┌─────────────────────────────────────────────────────────────────┐
│                      查询检索流程                                │
└─────────────────────────────────────────────────────────────────┘

     ┌─────────┐
     │ 用户问题 │  "华为的营收是多少？"
     └────┬────┘
          │
          ▼
┌─────────────────┐
│ Step 1: 关键词  │  LLM 提取关键词：["华为", "营收"]
└────────┬────────┘
          │
          ├────────────────────────────┐
          ▼                            ▼
┌─────────────────┐          ┌─────────────────┐
│ Step 2a: 图遍历 │          │ Step 2b: 向量检索│
│ (精确匹配+遍历) │          │ (相似度匹配)    │
└────────┬────────┘          └────────┬────────┘
          │                            │
          │  实体：华为公司             │  相似 Chunks
          │  邻居：营收、净利润...      │  相似实体描述
          │                            │
          ▼                            ▼
┌─────────────────────────────────────────┐
│         Step 3: 合并去重                 │
└────────────────┬────────────────────────┘
                 │
                 ▼
┌─────────────────────────────────────────┐
│         Step 4: LLM 生成回答             │
│  上下文 = 图遍历结果 + 向量检索结果       │
└────────────────┬────────────────────────┘
                 │
                 ▼
          ┌─────────┐
          │  答案   │  "华为2023年营收达到7000亿元..."
          └─────────┘
```

### 5.2 详细步骤

#### Step 1: LLM 提取关键词

```python
# 用户问题
question = "华为的营收是多少？"

# LLM 提取关键词
keywords = llm.extract_keywords(question)
# 返回：
{
    "high_level": ["财务表现", "收入情况"],  # 抽象概念
    "low_level": ["华为", "华为公司", "营收"]  # 具体实体
}
```

#### Step 2a: 图遍历检索

```python
# 1. 用 low_level 关键词匹配实体名
matched_entities = ["华为公司"]  # 精确匹配

# 2. 在 Neo4j 中遍历（1-2跳）
neighbors = neo4j.query("""
    MATCH (n {name: '华为公司'})-[r]-(m)
    RETURN m.name, r.type, m.description
    LIMIT 10
""")
# 返回：营收、净利润、消费者业务...

# 3. 从 KV Store 获取详细描述
descriptions = [kv_store.get(name) for name in neighbors]
```

#### Step 2b: 向量检索

```python
# 1. 问题向量化
query_vector = embedding_api.embed("华为的营收是多少？")

# 2. 相似度检索
similar_chunks = vector_db.search(query_vector, top_k=5)
similar_entities = entity_vector_db.search(query_vector, top_k=5)
```

#### Step 3: 合并结果

```python
# 图遍历结果
graph_results = ["华为公司描述...", "营收描述...", "净利润描述..."]

# 向量检索结果
vector_results = ["Chunk: 华为2023年营收...", "Chunk: 同比增长10%..."]

# 合并去重
context = deduplicate(graph_results + vector_results)
```

#### Step 4: LLM 生成回答

```python
prompt = f"""
基于以下信息回答问题：

{context}

问题：{question}
"""

answer = llm.generate(prompt)
# "根据资料，华为2023年营收达到7000亿元，同比增长10%..."
```

---

## 6. 存储架构

### 6.1 四种存储的分工

```
┌─────────────────────────────────────────────────────────────────┐
│                         存储架构                                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  ┌──────────────────┐    ┌──────────────────┐                   │
│  │    VectorDB      │    │     Neo4j        │                   │
│  │   (向量存储)      │    │   (图存储)       │                   │
│  ├──────────────────┤    ├──────────────────┤                   │
│  │ • Chunk 向量     │    │ • 实体节点       │                   │
│  │ • Entity 向量    │    │ • 关系边         │                   │
│  │ • Relation 向量  │    │ • 图结构遍历     │                   │
│  │                  │    │                  │                   │
│  │ 用途：相似度检索  │    │ 用途：关系遍历   │                   │
│  └──────────────────┘    └──────────────────┘                   │
│                                                                  │
│  ┌──────────────────┐    ┌──────────────────┐                   │
│  │   KV Storage     │    │  Doc Status      │                   │
│  │   (键值存储)      │    │  (文档状态)      │                   │
│  ├──────────────────┤    ├──────────────────┤                   │
│  │ • 实体详细描述    │    │ • 文档处理状态   │                   │
│  │ • 关系详细描述    │    │ • 增量更新标记   │                   │
│  │ • Chunk 原文     │    │                  │                   │
│  │                  │    │                  │                   │
│  │ 用途：内容存取    │    │ 用途：状态管理   │                   │
│  └──────────────────┘    └──────────────────┘                   │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### 6.2 数据流向

```
文档内容 ──→ 分块 ──→ Chunks ──→ 向量化 ──→ VectorDB
                         │
                         ▼
                   LLM 提取
                         │
              ┌──────────┼──────────┐
              ▼          ▼          ▼
           实体        关系       描述
              │          │          │
              ▼          ▼          ▼
           Neo4j      Neo4j     KV Store
          (节点)      (边)     (详细内容)
              │          │
              └────┬─────┘
                   ▼
              向量化 ──→ VectorDB
```

---

## 7. 配置参数详解

### 7.1 核心参数

```python
LightRAG(
    # === 存储配置 ===
    working_dir="./lightrag_data",  # 工作目录
    graph_storage="Neo4JStorage",  # 图存储类型
    vector_storage="NanoVectorDBStorage",  # 向量存储类型

    # === 分块参数 ===
    chunk_token_size=1200,  # 每块大小（tokens）
    chunk_overlap_token_size=100,  # 块重叠大小

    # === 性能参数 ===
    embedding_batch_num=32,  # 每批向量化数量
    embedding_func_max_async=4,  # 向量化并发数
    llm_model_max_async=4,  # LLM 并发数

    # === 语言配置 ===
    addon_params={"language": "Chinese"},  # 输出语言
)
```

### 7.2 参数影响

| 参数                         | 增大效果         | 减小效果       |
|----------------------------|--------------|------------|
| `chunk_token_size`         | 上下文更完整，提取更准确 | 检索更精细，速度更快 |
| `embedding_batch_num`      | 减少 API 调用次数  | 内存占用更小     |
| `embedding_func_max_async` | 并发更高，速度更快    | 避免 API 限流  |
| `llm_model_max_async`      | 实体提取更快       | 避免 API 限流  |

---

## 8. 实际示例

### 8.1 完整代码示例

```python
import asyncio
from lightrag import LightRAG, QueryParam
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.utils import EmbeddingFunc

# 1. 配置
WORKING_DIR = "./lightrag_data"
LLM_MODEL = "gpt-4"
EMBEDDING_MODEL = "text-embedding-3-small"


# 2. 初始化
async def main():
    # 创建 LightRAG 实例
    rag = LightRAG(
        working_dir=WORKING_DIR,
        llm_model_func=lambda prompt, **kwargs: openai_complete_if_cache(
            model=LLM_MODEL, prompt=prompt, **kwargs
        ),
        embedding_func=EmbeddingFunc(
            embedding_dim=1536,
            func=lambda texts: openai_embed(texts, model=EMBEDDING_MODEL),
        ),
        graph_storage="Neo4JStorage",
        addon_params={"language": "Chinese"},
    )

    # 初始化存储
    await rag.initialize_storages()

    # 3. 导入文档
    document = """
    华为公司成立于1987年，是全球领先的ICT基础设施和智能终端提供商。
    2023年，华为实现营业收入7042亿元人民币，同比增长9.6%。
    其中，ICT基础设施业务收入3620亿元，终端业务收入2515亿元。
    """

    await rag.ainsert(document)
    print("✅ 文档导入完成")

    # 4. 查询
    question = "华为2023年的营收是多少？各业务收入如何？"

    # 混合检索模式
    answer = await rag.aquery(
        question,
        param=QueryParam(mode="hybrid")
    )

    print(f"问题：{question}")
    print(f"回答：{answer}")


asyncio.run(main())
```

### 8.2 运行效果

```
🚀 正在初始化 LightRAG...
✅ LightRAG 初始化成功!

📄 正在处理文档...
   [1/3] 提取文本...
   ✓ 提取完成，共 156 字符
   [2/3] 正在索引 (实体提取 + 向量化)...
   📡 [3s] Phase 1: Processing 8 entities from doc-xxx (async: 4)
   📊 Phase 1 (entities) [████████████████████] 8/8 (100%)
   📡 [8s] Phase 2: Processing 5 relations from doc-xxx (async: 4)
   📊 Phase 2 (relations) [████████████████████] 5/5 (100%)
   ✅ [12s] Completed merging: 8 entities, 0 extra entities, 5 relations
   ✓ 索引完成! 实际 embedding: 45 条, 耗时 15.2s
   [3/3] ✅ 文档导入成功!

问题：华为2023年的营收是多少？各业务收入如何？

回答：根据资料，华为2023年实现营业收入7042亿元人民币，同比增长9.6%。
各业务收入如下：
- ICT基础设施业务：3620亿元
- 终端业务：2515亿元
```

### 8.3 生成的知识图谱

```
                    ┌───────────┐
                    │  华为公司  │
                    └─────┬─────┘
          ┌───────────────┼───────────────┐
          ▼               ▼               ▼
    ┌───────────┐   ┌───────────┐   ┌───────────┐
    │ ICT业务   │   │  终端业务  │   │   营收    │
    └─────┬─────┘   └─────┬─────┘   └─────┬─────┘
          ▼               ▼               ▼
    ┌───────────┐   ┌───────────┐   ┌───────────┐
    │ 3620亿元  │   │ 2515亿元  │   │ 7042亿元  │
    └───────────┘   └───────────┘   └───────────┘
```

---

## 总结

LightRAG 通过**向量检索 + 知识图谱**的混合架构，实现了：

1. **更准确的检索**：图遍历发现隐含关联
2. **更完整的上下文**：实体描述 + 原文块
3. **更好的可解释性**：知识图谱可视化

适用场景：

- 企业知识库问答
- 技术文档检索
- 研究论文分析
- 任何需要深度理解文档关系的场景
