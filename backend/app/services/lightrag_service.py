"""LightRAG æœåŠ¡å°è£…

ä¸ºæ°¸ç­–Proæ™ºèƒ½åŠ©æ‰‹æä¾›ä¼ä¸šçŸ¥è¯†åº“æ£€ç´¢èƒ½åŠ›ã€‚
æ”¯æŒæ··åˆæ£€ç´¢æ¨¡å¼ï¼ˆå‘é‡ + çŸ¥è¯†å›¾è°±ï¼‰ï¼Œæ¶µç›–æ°¸ç­–Proé¡¹ç›®çš„å…¨é‡æ–‡æ¡£ã€‚

é…ç½®è¯´æ˜ï¼š
- LLMï¼šå¤ç”¨ç³»ç»Ÿæ¿€æ´»çš„ AI æ¨¡å‹é…ç½®
- Embeddingï¼šæš‚æ—¶ç¡¬ç¼–ç ï¼ˆåç»­å¯è¿ç§»åˆ°æ•°æ®åº“é…ç½®ï¼‰
- Neo4jï¼šå¤ç”¨ç³»ç»Ÿçš„ neo4j_client é…ç½®
"""

import os
import re
import json
import asyncio
import logging
from pathlib import Path
from typing import Optional

from sqlalchemy.orm import Session
from starlette.websockets import WebSocket
from functools import partial

from lightrag import LightRAG, QueryParam
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.rerank import cohere_rerank
from lightrag.utils import EmbeddingFunc

from backend.app.services.ai_model_service import AIModelService
from backend.app.db.neo4j_client import (
    DEFAULT_NEO4J_URI,
    DEFAULT_NEO4J_USER,
    DEFAULT_NEO4J_PASSWORD,
)
from backend.app.core.logger import logger
from backend.app.core.lightrag_config import (
    LIGHTRAG_WORKING_DIR,
    LIGHTRAG_WORKSPACE,
    EMBEDDING_MODEL,
    EMBEDDING_API_KEY,
    EMBEDDING_BASE_URL,
    EMBEDDING_DIM,
    RERANK_MODEL,
    RERANK_API_KEY,
    RERANK_BASE_URL,
    CHUNK_TOKEN_SIZE,
    CHUNK_OVERLAP_TOKEN_SIZE,
    EMBEDDING_BATCH_NUM,
    EMBEDDING_FUNC_MAX_ASYNC,
    LLM_MODEL_MAX_ASYNC,
    KV_STORAGE,
    VECTOR_STORAGE,
    GRAPH_STORAGE,
    DOC_STATUS_STORAGE,
)


class LightRAGService:
    """LightRAG æœåŠ¡å•ä¾‹
    
    å°è£… LightRAG å®ä¾‹çš„åˆ›å»ºå’ŒæŸ¥è¯¢ï¼Œæä¾›ç»Ÿä¸€çš„æ“ä½œæ–‡æ¡£æ£€ç´¢æ¥å£ã€‚
    
    é…ç½®ç­–ç•¥ï¼š
    - LLMï¼šä»æ•°æ®åº“è·å–å½“å‰æ¿€æ´»çš„ AI æ¨¡å‹é…ç½®
    - Embeddingï¼šç¡¬ç¼–ç é…ç½®ï¼ˆæœªæ¥å¯æ‰©å±•åˆ°æ•°æ®åº“ï¼‰
    - Neo4jï¼šå¤ç”¨ç³»ç»Ÿç»Ÿä¸€é…ç½®
    """
    
    _instance: Optional[LightRAG] = None
    _db_session: Optional[Session] = None
    
    # è¿›åº¦æ¨é€ä¸Šä¸‹æ–‡ï¼ˆç±»å˜é‡ï¼Œç”¨äºè·¨å¼‚æ­¥ä»»åŠ¡ä¼ é€’ï¼‰
    _progress_websocket: Optional[WebSocket] = None
    _progress_tool_id: Optional[int] = None
    _progress_tool_name: Optional[str] = None
    
    @classmethod
    async def get_instance(cls, db: Session) -> LightRAG:
        """è·å– LightRAG å•ä¾‹å®ä¾‹ï¼ˆæ‡’åŠ è½½ï¼‰
        
        Args:
            db: æ•°æ®åº“ä¼šè¯ï¼Œç”¨äºè·å– LLM é…ç½®
        
        Returns:
            å·²åˆå§‹åŒ–çš„ LightRAG å®ä¾‹
        """
        if cls._instance is None:
            logger.info("[LightRAG] å¼€å§‹åˆå§‹åŒ– LightRAG å®ä¾‹...")
            cls._db_session = db
            cls._instance = await cls._create_instance(db)
            logger.info("[LightRAG] LightRAG å®ä¾‹åˆå§‹åŒ–å®Œæˆ")
        return cls._instance
    
    @classmethod
    async def _create_instance(cls, db: Session) -> LightRAG:
        """åˆ›å»ºå¹¶åˆå§‹åŒ– LightRAG å®ä¾‹
        
        Args:
            db: æ•°æ®åº“ä¼šè¯
        
        Returns:
            é…ç½®å¥½çš„ LightRAG å®ä¾‹
        """
        # è·å– LLM é…ç½®ï¼ˆä¼˜å…ˆä½¿ç”¨å°ä»»åŠ¡æ¨¡å‹ï¼Œæœªé…ç½®åˆ™ fallback åˆ°ä¸»åŠ›æ¨¡å‹ï¼‰
        try:
            task_model = AIModelService.get_task_active_model(db)
            llm_config = AIModelService.get_task_llm_config(db)
            if task_model:
                logger.info(f"[LightRAG] ä½¿ç”¨å°ä»»åŠ¡ LLM é…ç½®: model={llm_config.model_name}")
            else:
                logger.info(f"[LightRAG] æœªé…ç½®å°ä»»åŠ¡æ¨¡å‹ï¼Œfallback ä½¿ç”¨ä¸»åŠ› LLM: model={llm_config.model_name}")
        except RuntimeError as e:
            logger.error(f"[LightRAG] è·å– LLM é…ç½®å¤±è´¥: {e}")
            raise
        
        # è®¾ç½® Neo4j ç¯å¢ƒå˜é‡ï¼ˆLightRAG å†…éƒ¨éœ€è¦ï¼‰
        os.environ["NEO4J_URI"] = DEFAULT_NEO4J_URI
        os.environ["NEO4J_USERNAME"] = DEFAULT_NEO4J_USER
        os.environ["NEO4J_PASSWORD"] = DEFAULT_NEO4J_PASSWORD
        os.environ["OPENAI_API_KEY"] = llm_config.api_key  # LightRAG è¦æ±‚å¿…é¡»è®¾ç½®
        
        logger.info(f"[LightRAG] Neo4j é…ç½®: uri={DEFAULT_NEO4J_URI}, workspace={LIGHTRAG_WORKSPACE}")
        
        # ç¡®ä¿å·¥ä½œç›®å½•å­˜åœ¨
        os.makedirs(LIGHTRAG_WORKING_DIR, exist_ok=True)
        
        # è‡ªå®šä¹‰ LLM å‡½æ•°ï¼ˆå¤ç”¨ç³»ç»Ÿé…ç½®ï¼‰
        async def llm_func(prompt, system_prompt=None, history_messages=[], **kwargs):
            # å¤„ç† base_urlï¼šLightRAG çš„ openai_complete_if_cache ä¼šè‡ªåŠ¨åŠ  /chat/completions
            base_url = llm_config.base_url
            
            # è‡ªå®šä¹‰ç½‘å…³æ¨¡å¼
            if llm_config.provider_type == "custom_gateway" and llm_config.gateway_endpoint:
                base_url = llm_config.gateway_endpoint.rstrip("/")
                
                # LightRAG ä¼šè‡ªåŠ¨è¿½åŠ  /chat/completionsï¼Œå› æ­¤å¦‚æœ endpoint å·²ç»åŒ…å«äº†è¯¥è·¯å¾„ï¼Œéœ€è¦ç§»é™¤
                if base_url.endswith("/chat/completions"):
                    base_url = base_url[:-17]  # len("/chat/completions") == 17
                elif base_url.endswith("/chat/completions/"):
                    base_url = base_url[:-18]
                
                # ç¡®ä¿ä»¥ /v1 ç»“å°¾ï¼ˆä½†ä¸åŒ…å« /chat/completionsï¼‰
                if not base_url.endswith("/v1"):
                    base_url = base_url + "/v1"
            
            return await openai_complete_if_cache(
                model=llm_config.model_name,
                prompt=prompt,
                system_prompt=system_prompt,
                history_messages=history_messages,
                api_key=llm_config.api_key,
                base_url=base_url,
                **kwargs
            )
        
        # è‡ªå®šä¹‰ Embedding å‡½æ•°ï¼ˆä½¿ç”¨ç»Ÿä¸€é…ç½®ï¼‰
        async def embedding_func(texts: list[str]):
            logger.debug(f"[LightRAG] Embedding: {len(texts)} texts, model={EMBEDDING_MODEL}")
            
            # ğŸ”¥ ä¸»åŠ¨æ¨é€ Embedding è¿›åº¦
            ws = cls._progress_websocket
            tool_id = cls._progress_tool_id
            tool_name = cls._progress_tool_name
            if ws and tool_id is not None:
                try:
                    loop = asyncio.get_running_loop()
                    # æ ¹æ®æ–‡æœ¬æ•°é‡è°ƒæ•´æè¿°
                    if len(texts) == 1:
                        detail = "æ­£åœ¨åˆ†ææ–‡æœ¬è¯­ä¹‰..."
                    else:
                        detail = f"æ­£åœ¨å¤„ç† {len(texts)} æ®µå†…å®¹..."
                    
                    asyncio.run_coroutine_threadsafe(
                        cls._send_progress(ws, tool_name, tool_id, "embedding", detail),
                        loop
                    )
                except RuntimeError:
                    pass
            
            return await openai_embed(
                texts,
                model=EMBEDDING_MODEL,
                api_key=EMBEDDING_API_KEY,
                base_url=EMBEDDING_BASE_URL,
            )
        
        # é…ç½® Rerank å‡½æ•°ï¼ˆç¡…åŸºæµåŠ¨å¹³å°ï¼Œå…¼å®¹ Cohere APIï¼‰
        rerank_func = partial(
            cohere_rerank,
            model=RERANK_MODEL,
            api_key=RERANK_API_KEY,
            base_url=RERANK_BASE_URL,
        )
        logger.info(f"[LightRAG] Rerank é…ç½®: model={RERANK_MODEL}")
        
        # é…ç½® LightRAG çš„å†…éƒ¨æ—¥å¿—çº§åˆ«
        cls._configure_lightrag_logging()
        
        # åˆ›å»º LightRAG å®ä¾‹
        rag = LightRAG(
            working_dir=LIGHTRAG_WORKING_DIR,
            workspace=LIGHTRAG_WORKSPACE,
            
            # LLM é…ç½®
            llm_model_func=llm_func,
            
            # Embedding é…ç½®
            embedding_func=EmbeddingFunc(
                embedding_dim=EMBEDDING_DIM,
                max_token_size=8192,
                func=embedding_func,
            ),
            
            # Rerank é…ç½®
            rerank_model_func=rerank_func,
            
            # å­˜å‚¨é…ç½®
            graph_storage=GRAPH_STORAGE,
            vector_storage=VECTOR_STORAGE,
            kv_storage=KV_STORAGE,
            doc_status_storage=DOC_STATUS_STORAGE,
            
            # æ€§èƒ½å‚æ•°
            chunk_token_size=CHUNK_TOKEN_SIZE,
            chunk_overlap_token_size=CHUNK_OVERLAP_TOKEN_SIZE,
            embedding_batch_num=EMBEDDING_BATCH_NUM,
            embedding_func_max_async=EMBEDDING_FUNC_MAX_ASYNC,
            llm_model_max_async=LLM_MODEL_MAX_ASYNC,
            
            # è¯­è¨€é…ç½®
            addon_params={
                "language": "Chinese",
            },
        )
        
        # åˆå§‹åŒ–å­˜å‚¨
        await rag.initialize_storages()
        
        # åˆå§‹åŒ– pipeline çŠ¶æ€ï¼ˆé‡è¦ï¼ï¼‰
        try:
            from lightrag.kg.shared_storage import initialize_pipeline_status
            await initialize_pipeline_status()
            logger.debug("[LightRAG] Pipeline çŠ¶æ€åˆå§‹åŒ–å®Œæˆ")
        except ImportError:
            logger.warning("[LightRAG] æ— æ³•å¯¼å…¥ initialize_pipeline_statusï¼Œè·³è¿‡")
        except Exception as e:
            logger.warning(f"[LightRAG] Pipeline çŠ¶æ€åˆå§‹åŒ–å¤±è´¥: {e}")
        
        logger.info(
            f"[LightRAG] å­˜å‚¨åˆå§‹åŒ–å®Œæˆ: "
            f"working_dir={LIGHTRAG_WORKING_DIR}, "
            f"workspace={LIGHTRAG_WORKSPACE}, "
            f"llm={llm_config.model_name}, "
            f"embedding={EMBEDDING_MODEL}, "
            f"rerank={RERANK_MODEL}"
        )
        
        return rag
    
    @classmethod
    def _configure_lightrag_logging(cls):
        """é…ç½® LightRAG å†…éƒ¨æ—¥å¿—ï¼Œä½¿å…¶è¾“å‡ºåˆ°æˆ‘ä»¬çš„ logger
        
        LightRAG å†…éƒ¨ä½¿ç”¨æ ‡å‡†çš„ logging æ¨¡å—ï¼Œæˆ‘ä»¬å°†å…¶æ—¥å¿—
        æ¡¥æ¥åˆ°ç³»ç»Ÿçš„ loguru loggerï¼ŒåŒæ—¶è§£æé˜¶æ®µä¿¡æ¯ç”¨äºè¿›åº¦è¿½è¸ªã€‚
        """
        # è·å– LightRAG çš„ logger
        lightrag_logger = logging.getLogger("lightrag")
        
        # è®¾ç½®æ—¥å¿—çº§åˆ«
        lightrag_logger.setLevel(logging.INFO)
        
        # æ¸…é™¤ç°æœ‰ handlersï¼Œé¿å…é‡å¤è¾“å‡º
        lightrag_logger.handlers.clear()
        
        # æ·»åŠ è‡ªå®šä¹‰ handlerï¼Œæ¡¥æ¥åˆ° loguru å¹¶è§£æé˜¶æ®µ
        class LoguruHandler(logging.Handler):
            """å°† logging æ—¥å¿—æ¡¥æ¥åˆ° loguruï¼ŒåŒæ—¶è§£æé˜¶æ®µä¿¡æ¯å¹¶æ¨é€ WebSocket è¿›åº¦"""
            
            def emit(self, record):
                # è·å–å¯¹åº”çš„ loguru çº§åˆ«
                try:
                    level = logger.level(record.levelname).name
                except ValueError:
                    level = record.levelno
                
                # æ ¼å¼åŒ–æ¶ˆæ¯
                message = self.format(record)
                
                # è§£æé˜¶æ®µä¿¡æ¯å¹¶æ¨é€ WebSocket
                phase_info = cls._parse_lightrag_phase(message)
                if phase_info:
                    phase, detail = phase_info
                    logger.info(f"[LightRAG:Phase] é˜¶æ®µ={phase}, è¯¦æƒ…={detail}")
                    
                    # å°è¯•æ¨é€ WebSocket è¿›åº¦æ¶ˆæ¯ï¼ˆä½¿ç”¨ç±»å˜é‡ï¼‰
                    ws = cls._progress_websocket
                    tool_id = cls._progress_tool_id
                    tool_name = cls._progress_tool_name
                    logger.info(f"[LightRAG:Phase] è¿›åº¦ä¸Šä¸‹æ–‡: ws={ws is not None}, tool_id={tool_id}, tool_name={tool_name}")
                    if ws and tool_id is not None:
                        try:
                            # è·å–äº‹ä»¶å¾ªç¯å¹¶åˆ›å»ºä»»åŠ¡å‘é€æ¶ˆæ¯
                            loop = asyncio.get_running_loop()
                            logger.info(f"[LightRAG:Phase] å‡†å¤‡æ¨é€è¿›åº¦: phase={phase}")
                            asyncio.run_coroutine_threadsafe(
                                cls._send_progress(ws, tool_name, tool_id, phase, detail),
                                loop
                            )
                        except RuntimeError as e:
                            # æ²¡æœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œè·³è¿‡æ¨é€
                            logger.warning(f"[LightRAG:Phase] æ— æ³•è·å–äº‹ä»¶å¾ªç¯: {e}")
                    else:
                        logger.debug(f"[LightRAG:Phase] è·³è¿‡æ¨é€: wsæˆ–tool_idæœªè®¾ç½®")
                
                # è¾“å‡ºåˆ° loguruï¼ˆæ·»åŠ  [LightRAG] å‰ç¼€ï¼‰
                logger.opt(depth=6, exception=record.exc_info).log(
                    level, f"[LightRAG] {message}"
                )
        
        handler = LoguruHandler()
        handler.setFormatter(logging.Formatter("%(message)s"))
        lightrag_logger.addHandler(handler)
        
        # é˜»æ­¢å‘ä¸Šä¼ æ’­åˆ° root logger
        lightrag_logger.propagate = False
        
        logger.debug("[LightRAG] å·²é…ç½® LightRAG å†…éƒ¨æ—¥å¿—æ¡¥æ¥")
    
    @classmethod
    def _parse_lightrag_phase(cls, message: str) -> tuple[str, str] | None:
        """è§£æ LightRAG æ—¥å¿—ä¸­çš„é˜¶æ®µä¿¡æ¯
        
        Args:
            message: LightRAG çš„æ—¥å¿—æ¶ˆæ¯
            
        Returns:
            (phase, detail) å…ƒç»„ï¼Œæˆ– None è¡¨ç¤ºä¸æ˜¯é˜¶æ®µæ—¥å¿—
        """
        # ğŸ”¥ æ–°å¢ï¼šWorkers åˆå§‹åŒ–
        match = re.search(r'(LLM|Embedding) func: (\d+) new workers initialized', message)
        if match:
            worker_type = "æ™ºèƒ½åˆ†æ" if match.group(1) == "LLM" else "æ–‡æœ¬å¤„ç†"
            return ("init_workers", f"å‡†å¤‡{worker_type}å¼•æ“...")
        
        # ğŸ”¥ æ–°å¢ï¼šå…³é”®è¯æå–å¼€å§‹ï¼ˆæ•è·LLMè¯·æ±‚ï¼‰
        if 'keyword extractor' in message.lower() and 'User Query:' in message:
            return ("extracting_keywords", "æ­£åœ¨ç†è§£æ‚¨çš„é—®é¢˜...")
        
        # ğŸ”¥ æ–°å¢ï¼šå…³é”®è¯æå–å®Œæˆ
        if ' == LLM cache == saving:' in message and ':keywords:' in message:
            return ("keywords_extracted", "å·²è¯†åˆ«é—®é¢˜è¦ç‚¹")
        
        # ğŸ”¥ æ–°å¢ï¼šQuery nodesï¼ˆå®ä½“æŸ¥è¯¢ï¼‰
        match = re.search(r'Query nodes: ([^(]+) \(top_k:(\d+)', message)
        if match:
            keywords = match.group(1).strip()
            # æˆªæ–­å…³é”®è¯æ˜¾ç¤º
            keywords_short = keywords[:20] + '...' if len(keywords) > 20 else keywords
            return ("querying_entities", f"æŸ¥æ‰¾ä¸ \"{keywords_short}\" ç›¸å…³çš„å†…å®¹")
        
        # ğŸ”¥ æ–°å¢ï¼šQuery edgesï¼ˆå…³ç³»æŸ¥è¯¢ï¼‰
        match = re.search(r'Query edges: ([^(]+) \(top_k:(\d+)', message)
        if match:
            return ("querying_relations", "åˆ†æå†…å®¹ä¹‹é—´çš„å…³è”...")
        
        # ğŸ”¥ æ–°å¢ï¼šNaive queryï¼ˆçº¯å‘é‡æ£€ç´¢ï¼‰
        match = re.search(r'Naive query: (\d+) chunks', message)
        if match:
            chunk_count = match.group(1)
            return ("vector_search", f"æ‰¾åˆ° {chunk_count} æ®µç›¸å…³å†…å®¹")
        
        # Local query é˜¶æ®µ
        match = re.match(r'Local query: (\d+) entites?, (\d+) relations?', message)
        if match:
            total = int(match.group(1)) + int(match.group(2))
            return ("local_query", f"å·²å®šä½ {total} æ¡ç›¸å…³ä¿¡æ¯")
        
        # Global query é˜¶æ®µ
        match = re.match(r'Global query: (\d+) entites?, (\d+) relations?', message)
        if match:
            total = int(match.group(1)) + int(match.group(2))
            return ("global_query", f"æ‰©å±•æœç´¢ï¼Œç´¯è®¡ {total} æ¡ä¿¡æ¯")
        
        # Rerank é˜¶æ®µ
        match = re.match(r'Successfully reranked: (\d+) chunks from (\d+)', message)
        if match:
            selected = match.group(1)
            return ("rerank", f"ä»æµ·é‡å†…å®¹ä¸­ç²¾é€‰å‡ºæœ€ç›¸å…³çš„ {selected} æ¡")
        
        # Final context é˜¶æ®µ
        match = re.match(r'Final context: (\d+) entities?, (\d+) relations?, (\d+) chunks?', message)
        if match:
            chunks = match.group(3)
            return ("finalize", f"æ­£åœ¨æ•´ç† {chunks} æ¡å†…å®¹ä¸ºæ‚¨å‡†å¤‡ç­”æ¡ˆ")
        
        # Raw search resultsï¼ˆæ£€ç´¢å®Œæˆï¼‰
        match = re.match(r'Raw search results: (\d+) entities?, (\d+) relations?, (\d+) vector chunks?', message)
        if match:
            chunks = match.group(3)
            return ("search_complete", f"æ£€ç´¢å®Œæˆï¼Œå…±æ‰¾åˆ° {chunks} æ®µç›¸å…³å†…å®¹")
        
        # ğŸ”¥ æ–°å¢ï¼šSelecting chunks (å‘é‡ç›¸ä¼¼åº¦ç­›é€‰)
        match = re.search(r'Selecting (\d+) from (\d+) (entity|relation)-related chunks', message)
        if match:
            selected = match.group(1)
            total = match.group(2)
            return ("selecting_chunks", f"ä» {total} æ¡ä¸­ç­›é€‰å‡º {selected} æ¡æœ€ç›¸å…³å†…å®¹")
        
        return None
    
    @classmethod
    async def _send_progress(cls, ws: WebSocket, tool_name: str, tool_id: int, phase: str, detail: str):
        """å‘é€ tool_progress æ¶ˆæ¯åˆ° WebSocket
        
        Args:
            ws: WebSocket è¿æ¥
            tool_name: å·¥å…·åç§°
            tool_id: å·¥å…·å ä½ç¬¦ ID
            phase: é˜¶æ®µåç§°
            detail: é˜¶æ®µè¯¦æƒ…
        """
        try:
            await ws.send_text(json.dumps({
                "type": "tool_progress",
                "tool_name": tool_name,
                "tool_id": tool_id,
                "phase": phase,
                "detail": detail,
            }, ensure_ascii=False))
            logger.debug(f"[LightRAG] å·²æ¨é€è¿›åº¦: phase={phase}")
        except Exception as e:
            logger.warning(f"[LightRAG] æ¨é€è¿›åº¦å¤±è´¥: {e}")
    
    @classmethod
    def set_progress_context(cls, ws: Optional[WebSocket], tool_id: Optional[int], tool_name: Optional[str] = None):
        """è®¾ç½®è¿›åº¦æ¨é€çš„ä¸Šä¸‹æ–‡
        
        åœ¨å·¥å…·æ‰§è¡Œå‰è°ƒç”¨ï¼Œè®¾ç½® WebSocket å’Œ tool_idï¼Œ
        ä½¿å¾— LightRAG å†…éƒ¨æ—¥å¿—æ•è·æ—¶èƒ½æ¨é€è¿›åº¦æ¶ˆæ¯ã€‚
        
        Args:
            ws: WebSocket è¿æ¥ï¼ŒNone è¡¨ç¤ºæ¸…é™¤
            tool_id: å·¥å…·å ä½ç¬¦ ID
            tool_name: å·¥å…·åç§°
        """
        cls._progress_websocket = ws
        cls._progress_tool_id = tool_id
        cls._progress_tool_name = tool_name
    
    @classmethod
    def clear_progress_context(cls):
        """æ¸…é™¤è¿›åº¦æ¨é€çš„ä¸Šä¸‹æ–‡"""
        cls._progress_websocket = None
        cls._progress_tool_id = None
        cls._progress_tool_name = None
    
    @classmethod
    def invalidate(cls) -> None:
        """æ¸…é™¤ LightRAG å•ä¾‹å®ä¾‹
        
        ç”¨äº LLM é…ç½®å˜æ›´åå¼ºåˆ¶é‡å»ºå®ä¾‹ï¼Œç¡®ä¿ä½¿ç”¨æ–°çš„ LLM é…ç½®ã€‚
        ä¸‹æ¬¡è°ƒç”¨ get_instance() æ—¶ä¼šè‡ªåŠ¨é‡æ–°åˆ›å»ºå®ä¾‹ã€‚
        """
        if cls._instance is not None:
            logger.info("[LightRAG] æ¸…é™¤å®ä¾‹ç¼“å­˜ï¼Œä¸‹æ¬¡è¯·æ±‚å°†ä½¿ç”¨æ–° LLM é…ç½®é‡å»º")
            cls._instance = None
            cls._db_session = None
        else:
            logger.debug("[LightRAG] å®ä¾‹æœªåˆå§‹åŒ–ï¼Œæ— éœ€æ¸…é™¤")
    
    @classmethod
    async def warmup(cls, db: Session) -> None:
        """é¢„çƒ­ LightRAG å®ä¾‹
        
        åœ¨åº”ç”¨å¯åŠ¨æ—¶è°ƒç”¨ï¼Œæå‰åˆå§‹åŒ– LightRAG å®ä¾‹ï¼Œé¿å…é¦–æ¬¡æŸ¥è¯¢æ—¶ç­‰å¾…ã€‚
        
        Args:
            db: æ•°æ®åº“ä¼šè¯
        """
        try:
            logger.info("[LightRAG] å¼€å§‹é¢„çƒ­...")
            await cls.get_instance(db)
            logger.info("[LightRAG] é¢„çƒ­å®Œæˆï¼Œå®ä¾‹å·²å°±ç»ª")
        except Exception as e:
            logger.warning(f"[LightRAG] é¢„çƒ­å¤±è´¥ï¼ˆé¦–æ¬¡æŸ¥è¯¢æ—¶ä¼šè‡ªåŠ¨åˆå§‹åŒ–ï¼‰: {e}")
    
    @classmethod
    async def search_context(cls, question: str, db: Session, mode: str = "mix") -> dict:
        """æ£€ç´¢æ°¸ç­–Proä¼ä¸šçŸ¥è¯†åº“ä¸Šä¸‹æ–‡ï¼ˆåªè¿”å›æ£€ç´¢ç»“æœï¼Œä¸ç”Ÿæˆå›ç­”ï¼‰
        
        ä½¿ç”¨ LightRAG çš„å¤šç§æ£€ç´¢æ¨¡å¼æ£€ç´¢æ°¸ç­–Proé¡¹ç›®çš„ç›¸å…³æ–‡æ¡£å†…å®¹ã€‚
        
        Args:
            question: ç”¨æˆ·é—®é¢˜ï¼Œå¦‚ "æƒé™ç®¡ç†åŠŸèƒ½è¯´æ˜"ã€"è®¢å•æµç¨‹è®¾è®¡"
            mode: æ£€ç´¢æ¨¡å¼ï¼Œå¯é€‰å€¼ï¼š
                  - naive: çº¯å‘é‡æ£€ç´¢ï¼ˆæœ€å¿«ï¼‰
                  - local: å®ä½“ä¸­å¿ƒå›¾è°±æ£€ç´¢ï¼ˆå¸¸ç”¨ï¼‰
                  - global: å…³ç³»ä¸­å¿ƒå›¾è°±æ£€ç´¢
                  - hybrid: æ·±åº¦å›¾è°±æ¨ç†ï¼ˆæœ€å…¨ï¼‰
                  - mix: å¹³è¡¡æ¨¡å¼ï¼ˆé»˜è®¤ï¼Œæ¨èï¼‰
            
        Returns:
            {
                "context": "æ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹...",
                "sources": ["æ–‡æ¡£1", "æ–‡æ¡£2"]  # æ¥æºæ–‡æ¡£åˆ—è¡¨
            }
        """
        try:
            rag = await cls.get_instance(db)
            
            logger.info(f"[LightRAG] å¼€å§‹æ£€ç´¢: question={question[:50]}..., mode={mode}")
            
            # ğŸ”¥ ç«‹å³æ¨é€å¼€å§‹æ£€ç´¢çš„è¿›åº¦
            ws = cls._progress_websocket
            tool_id = cls._progress_tool_id
            tool_name = cls._progress_tool_name
            if ws and tool_id is not None:
                try:
                    # æˆªæ–­é—®é¢˜æ˜¾ç¤ºï¼Œæ›´ç®€æ´å‹å¥½
                    question_short = question[:15] + '...' if len(question) > 15 else question
                    await cls._send_progress(
                        ws, tool_name, tool_id,
                        "start_search",
                        f"å¼€å§‹ä¸ºæ‚¨æŸ¥æ‰¾å…³äºã€Œ{question_short}ã€çš„ä¿¡æ¯"
                    )
                except Exception as e:
                    logger.warning(f"[LightRAG] æ¨é€å¼€å§‹è¿›åº¦å¤±è´¥: {e}")
            
            # æ ¹æ®æ¨¡å¼åŠ¨æ€è°ƒæ•´ chunk_top_k
            chunk_top_k_map = {
                "naive": 20,    # çº¯å‘é‡ï¼Œå°‘ä¸€äº›
                "local": 30,    # å±€éƒ¨å›¾è°±
                "global": 40,   # å…¨å±€å›¾è°±
                "hybrid": 50,   # æ·±åº¦åˆ†æï¼Œå¤šä¸€äº›
                "mix": 40,      # å¹³è¡¡æ¨¡å¼
            }
            chunk_top_k = chunk_top_k_map.get(mode, 40)
            
            # è°ƒç”¨ LightRAG æŸ¥è¯¢ï¼ˆonly_need_context=True åªè¿”å›æ£€ç´¢ç»“æœï¼‰
            context = await rag.aquery(
                question,
                param=QueryParam(
                    mode=mode,
                    only_need_context=True,  # åªè¿”å›ä¸Šä¸‹æ–‡ï¼Œä¸ç”Ÿæˆå›ç­”
                    chunk_top_k=chunk_top_k
                )
            )
            
            # æ£€æŸ¥è¿”å›ç»“æœæ˜¯å¦ä¸º Noneï¼ˆæŸ¥è¯¢å¤±è´¥ï¼‰
            if context is None:
                logger.error(f"[LightRAG] æŸ¥è¯¢è¿”å› Noneï¼Œå¯èƒ½æ˜¯ LLM è°ƒç”¨å¤±è´¥")
                return {
                    "context": "",
                    "sources": [],
                    "error": "LLM è°ƒç”¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥ LLM é…ç½®"
                }
            
            if not context:
                logger.warning(f"[LightRAG] æ£€ç´¢ç»“æœä¸ºç©º")
                return {
                    "context": "",
                    "sources": []
                }
            
            # æå–æ¥æºæ–‡æ¡£
            sources = cls._extract_sources(context)
            
            logger.info(f"[LightRAG] æ£€ç´¢å®Œæˆ: context_length={len(context)}, sources={len(sources)}")
            
            return {
                "context": context,
                "sources": sources
            }
        
        except Exception as e:
            logger.error(f"[LightRAG] æ£€ç´¢å¤±è´¥: {e}")
            return {
                "context": "",
                "sources": [],
                "error": str(e),
            }
    
    @classmethod
    def _extract_sources(cls, context: str) -> list[dict]:
        """ä» context ä¸­æå– LightRAG çš„ Reference Document List
        
        LightRAG åœ¨ context æœ«å°¾ä¼šé™„åŠ  Reference Document Listï¼Œæ ¼å¼å¦‚ï¼š
        [1] æ–‡æ¡£åç§° (https://xxx/doc/ABC123)
        [2] å¦ä¸€ä¸ªæ–‡æ¡£ (https://xxx/doc/DEF456)
        
        Args:
            context: LightRAG è¿”å›çš„ä¸Šä¸‹æ–‡æ–‡æœ¬
            
        Returns:
            å»é‡åçš„æ¥æºæ–‡æ¡£åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º {"name": "æ–‡æ¡£å", "url": "æ–‡æ¡£åœ°å€"}
        """
        sources = []
        seen = set()
        
        # æ ¼å¼: [æ•°å­—] æ–‡æ¡£åç§° (URL)
        matches = re.findall(r'\[\d+\]\s*([^(\n]+?)\s*\((https?://[^)]+)\)', context)
        for name, url in matches:
            name = name.strip()
            url = url.strip()
            if url not in seen:
                seen.add(url)
                sources.append({"name": name, "url": url})
        
        return sources
    
