"""ä¼šè¯å†å²ç®¡ç†æœåŠ¡

è´Ÿè´£ LangChain Agent å¯¹è¯å†å²çš„ç®¡ç†ï¼š
- è·å–/æ¸…é™¤/æˆªæ–­å†å²
- æ›¿æ¢ AI å›å¤
- ç”Ÿæˆä¼šè¯æ ‡é¢˜
"""

from typing import Dict, List
import uuid

from sqlalchemy.orm import Session
from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver
from langchain_core.messages import HumanMessage, AIMessage

from backend.app.llm.factory import get_lite_task_llm
from backend.app.models.chat import Conversation
from backend.app.core.logger import logger
from backend.app.llm.langchain.agent import get_agent_config


async def get_conversation_history(thread_id: str) -> List[Dict[str, str]]:
    """è·å–ä¼šè¯å†å²
    
    Args:
        thread_id: ä¼šè¯ ID
        
    Returns:
        æ¶ˆæ¯åˆ—è¡¨ [{"role": "user"|"assistant"|"tool", "content": "..."}]
    """
    return await get_thread_history(thread_id)


async def clear_conversation(thread_id: str) -> bool:
    """æ¸…é™¤ä¼šè¯å†å²
    
    Args:
        thread_id: ä¼šè¯ ID
        
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    return await clear_thread_history(thread_id)


async def truncate_conversation(thread_id: str, keep_pairs: int) -> bool:
    """æˆªæ–­ä¼šè¯å†å²ï¼Œåªä¿ç•™å‰ N å¯¹å¯¹è¯
    
    Args:
        thread_id: ä¼šè¯ ID
        keep_pairs: ä¿ç•™çš„å¯¹è¯å¯¹æ•°
        
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    return await truncate_thread_history(thread_id, keep_pairs)


async def clear_thread_history(thread_id: str) -> bool:
    """æ¸…é™¤æŒ‡å®šä¼šè¯çš„å¯¹è¯å†å²
    
    Args:
        thread_id: ä¼šè¯ ID
        
    Returns:
        æ˜¯å¦æˆåŠŸæ¸…é™¤
    """
    try:
        # å½“å‰å®ç°ä»…è®°å½•æ—¥å¿—ï¼Œä¸å¯¹åº•å±‚æ£€æŸ¥ç‚¹åšå®é™…åˆ é™¤æ“ä½œ
        # å¦‚éœ€çœŸæ­£æ¸…é™¤ï¼Œå¯åœ¨æ­¤å¤„æ–°å¢åŸºäº AsyncSqliteSaver çš„åˆ é™¤é€»è¾‘
        logger.info(f"[HistoryService] æ¸…é™¤ä¼šè¯å†å²: thread_id={thread_id}")
        return True
    except Exception as e:
        logger.error(f"[HistoryService] æ¸…é™¤ä¼šè¯å†å²å¤±è´¥: {e}")
        return False


async def truncate_thread_history(thread_id: str, keep_pairs: int) -> bool:
    """æˆªæ–­ä¼šè¯å†å²ï¼Œåªä¿ç•™å‰ N å¯¹å¯¹è¯
    
    Args:
        thread_id: ä¼šè¯ ID
        keep_pairs: ä¿ç•™çš„å¯¹è¯å¯¹æ•°ï¼ˆä¸€å¯¹ = ä¸€ä¸ª user + å¯¹åº”çš„ assistant/tool æ¶ˆæ¯ï¼‰
        
    Returns:
        æ˜¯å¦æˆåŠŸæˆªæ–­
    """
    try:
        async with AsyncSqliteSaver.from_conn_string("llm_checkpoints.db") as memory:
            config = get_agent_config(thread_id)
            
            # ä½¿ç”¨ aget_tuple è·å–å®Œæ•´çš„æ£€æŸ¥ç‚¹ä¿¡æ¯ï¼ˆåŒ…å« metadataï¼‰
            checkpoint_tuple = await memory.aget_tuple(config)
            
            if not checkpoint_tuple or not checkpoint_tuple.checkpoint:
                logger.warning(f"[HistoryService] ä¼šè¯ä¸å­˜åœ¨: thread_id={thread_id}")
                return False
            
            checkpoint = checkpoint_tuple.checkpoint
            if "channel_values" not in checkpoint:
                logger.warning(f"[HistoryService] æ£€æŸ¥ç‚¹æ ¼å¼å¼‚å¸¸: thread_id={thread_id}")
                return False
            
            messages = checkpoint["channel_values"].get("messages", [])
            if not messages:
                return True
            
            # ç»Ÿè®¡å¯¹è¯å¯¹æ•°ï¼Œæ‰¾åˆ°æˆªæ–­ä½ç½®
            # æ¯é‡åˆ°ä¸€ä¸ª human æ¶ˆæ¯ç®—ä¸€å¯¹çš„å¼€å§‹
            pair_count = 0
            cut_index = 0
            
            for i, msg in enumerate(messages):
                msg_type = getattr(msg, "type", None)
                if msg_type == "human":
                    pair_count += 1
                    if pair_count > keep_pairs:
                        cut_index = i
                        break
            else:
                # æ²¡æœ‰è¶…å‡ºï¼Œæ— éœ€æˆªæ–­
                return True
            
            # æˆªæ–­æ¶ˆæ¯åˆ—è¡¨
            truncated_messages = messages[:cut_index]
            checkpoint["channel_values"]["messages"] = truncated_messages
            
            # ä½¿ç”¨åŸ checkpoint_tuple çš„ config å’Œ metadata æ¥æ›´æ–°
            await memory.aput(
                checkpoint_tuple.config,
                checkpoint,
                checkpoint_tuple.metadata,
                {}  # new_versions
            )
            
            logger.info(f"[HistoryService] æˆªæ–­ä¼šè¯å†å²: thread_id={thread_id}, ä¿ç•™ {keep_pairs} å¯¹, åŸæ¶ˆæ¯æ•° {len(messages)}, æˆªæ–­å {len(truncated_messages)}")
            return True
            
    except Exception as e:
        logger.error(f"[HistoryService] æˆªæ–­ä¼šè¯å†å²å¤±è´¥: {e}")
        return False


async def get_thread_history(thread_id: str) -> list:
    """è·å–æŒ‡å®šä¼šè¯çš„å¯¹è¯å†å²
    
    Args:
        thread_id: ä¼šè¯ ID
        
    Returns:
        æ¶ˆæ¯åˆ—è¡¨ï¼ŒåŒ…å« user/assistant/tool ç±»å‹æ¶ˆæ¯
        - role: "user" | "assistant" | "tool"
        - content: æ¶ˆæ¯å†…å®¹
        - tool_name: å·¥å…·åç§°ï¼ˆä»… tool ç±»å‹ï¼‰
        - tool_calls: å·¥å…·è°ƒç”¨ä¿¡æ¯ï¼ˆä»… assistant è°ƒç”¨å·¥å…·æ—¶ï¼‰
        - attachments: æ–‡ä»¶é™„ä»¶ï¼ˆä»…ç”¨æˆ·æ¶ˆæ¯ï¼Œä»å¤šæ¨¡æ€ content è§£æï¼‰
    """
    try:
        # ä¸ºæ¯æ¬¡æŸ¥è¯¢å•ç‹¬æ‰“å¼€ AsyncSqliteSaver ä¸Šä¸‹æ–‡
        async with AsyncSqliteSaver.from_conn_string("llm_checkpoints.db") as memory:
            config = get_agent_config(thread_id)
            
            # å°è¯•è·å–æ£€æŸ¥ç‚¹ï¼ˆå¼‚æ­¥ï¼‰
            checkpoint = await memory.aget(config)
        if checkpoint and "channel_values" in checkpoint:
            messages = checkpoint["channel_values"].get("messages", [])
            result = []
            for msg in messages:
                msg_type = getattr(msg, "type", None)
                content = getattr(msg, "content", "")
                
                if msg_type == "human":
                    # ä¼˜å…ˆä» additional_kwargs è·å–åŸå§‹é™„ä»¶ä¿¡æ¯
                    additional_kwargs = getattr(msg, "additional_kwargs", {}) or {}
                    original_attachments = additional_kwargs.get("original_attachments", [])
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ºç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆçš„æç¤ºæ¶ˆæ¯ï¼ˆä¸æ˜¾ç¤ºç»™ç”¨æˆ·ï¼‰
                    is_system_prompt = additional_kwargs.get("is_system_prompt", False)
                    if is_system_prompt:
                        logger.debug(f"[HistoryService] è·³è¿‡ç³»ç»Ÿæç¤ºæ¶ˆæ¯: {content[:50]}...")
                        continue
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰ç”¨æˆ·åŸå§‹æ¶ˆæ¯ï¼ˆintelligent_testing ç¬¬ä¸€é˜¶æ®µï¼‰
                    original_user_message = additional_kwargs.get("original_user_message")
                    if original_user_message:
                        logger.debug(f"[HistoryService] ä½¿ç”¨ç”¨æˆ·åŸå§‹æ¶ˆæ¯: {original_user_message[:50]}...")
                        result.append({"role": "user", "content": original_user_message})
                        continue
                    
                    if original_attachments:
                        # æœ‰åŸå§‹é™„ä»¶ä¿¡æ¯ï¼Œç›´æ¥ä½¿ç”¨
                        logger.info(f"[HistoryService] ä» additional_kwargs æ¢å¤ {len(original_attachments)} ä¸ªåŸå§‹é™„ä»¶")
                        # è§£æ content è·å–çº¯æ–‡æœ¬ï¼ˆè¿‡æ»¤æ‰è§£æåçš„æ–‡æ¡£å†…å®¹ï¼‰
                        text_content = _extract_user_question(content)
                        msg_data = {"role": "user", "content": text_content}
                        msg_data["attachments"] = original_attachments
                        result.append(msg_data)
                    else:
                        # æ²¡æœ‰åŸå§‹é™„ä»¶ä¿¡æ¯ï¼Œå›é€€åˆ°ä» content è§£æï¼ˆå…¼å®¹æ—§æ¶ˆæ¯ï¼‰
                        # logger.debug(f"[HistoryService] Human message content type: {type(content)}")
                        text_content, attachments = _parse_multimodal_content(content)
                        # logger.debug(f"[HistoryService] Parsed: text_len={len(text_content) if text_content else 0}, attachments_count={len(attachments)}")
                        msg_data = {"role": "user", "content": text_content}
                        if attachments:
                            msg_data["attachments"] = attachments
                        result.append(msg_data)
                elif msg_type == "ai":
                    # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                    tool_calls = getattr(msg, "tool_calls", None)
                    # AI æ¶ˆæ¯ content ä¹Ÿå¯èƒ½æ˜¯æ•°ç»„ï¼ˆå¤šæ¨¡æ€ï¼‰ï¼Œæå–æ–‡æœ¬
                    text_content = _extract_text_from_content(content)
                    if tool_calls:
                        # æœ‰å·¥å…·è°ƒç”¨çš„ AI æ¶ˆæ¯
                        result.append({
                            "role": "assistant",
                            "content": text_content,
                            "tool_calls": [
                                {"name": tc.get("name", ""), "args": tc.get("args", {})}
                                for tc in tool_calls
                            ]
                        })
                    else:
                        # æ™®é€š AI æ¶ˆæ¯
                        result.append({"role": "assistant", "content": text_content})
                elif msg_type == "tool":
                    # å·¥å…·è¿”å›æ¶ˆæ¯
                    tool_name = getattr(msg, "name", "unknown")
                    result.append({
                        "role": "tool",
                        "content": content if isinstance(content, str) else str(content),
                        "tool_name": tool_name
                    })
            
            return result
        return []
    except Exception as e:
        logger.error(f"[HistoryService] è·å–ä¼šè¯å†å²å¤±è´¥: {e}")
        return []


async def get_testing_history(session_id: str, db) -> dict:
    """è·å–æ™ºèƒ½æµ‹è¯•ä¼šè¯çš„å®Œæ•´å†å²
    
    åˆå¹¶ä¸‰ä¸ªé˜¶æ®µçš„æ¶ˆæ¯ï¼Œå¹¶è¿”å›ä»»åŠ¡é¢æ¿çŠ¶æ€æ•°æ®ã€‚
    
    Args:
        session_id: ä¼šè¯ ID
        db: æ•°æ®åº“ä¼šè¯
        
    Returns:
        {
            "messages": [...],  # åˆå¹¶åçš„æ¶ˆæ¯åˆ—è¡¨
            "phases": {...},    # é˜¶æ®µå®ŒæˆçŠ¶æ€
            "task_history": {...},  # ä»»åŠ¡å†å²ï¼ˆä» TestSessionTask æ¢å¤ï¼‰
        }
    """
    from backend.app.models.chat import Conversation, TestSessionAnalysis, TestSessionTask
    
    try:
        # 1. è·å–ä¼šè¯ä¿¡æ¯
        conv = db.query(Conversation).filter(
            Conversation.id == session_id,
            Conversation.agent_type == "intelligent_testing"
        ).first()
        
        if not conv:
            logger.warning(f"[HistoryService] æµ‹è¯•ä¼šè¯ä¸å­˜åœ¨: {session_id}")
            return {"messages": [], "phases": {}, "task_history": {}}
        
        # 2. è·å–é˜¶æ®µæ‘˜è¦ï¼Œåˆ¤æ–­é˜¶æ®µå®ŒæˆçŠ¶æ€
        summaries = db.query(TestSessionAnalysis).filter(
            TestSessionAnalysis.session_id == session_id
        ).all()
        summary_types = {s.analysis_type for s in summaries}
        
        # é˜¶æ®µå®ŒæˆçŠ¶æ€åŸºäºæ‘˜è¦æ˜¯å¦å­˜åœ¨
        phases_status = {
            "analysis": {
                "completed": "requirement_summary" in summary_types,
                "thread_id": conv.thread_id_analysis,
            },
            "plan": {
                "completed": "test_plan" in summary_types,
                "thread_id": conv.thread_id_plan,
            },
            "generate": {
                "completed": "test_cases" in summary_types,
                "thread_id": conv.thread_id_generate,
            },
        }
        
        # 3. æŒ‰é˜¶æ®µè·å–æ¶ˆæ¯å¹¶åˆå¹¶
        all_messages = []
        phase_configs = [
            ("analysis", conv.thread_id_analysis, "éœ€æ±‚åˆ†æ"),
            ("plan", conv.thread_id_plan, "æ–¹æ¡ˆç”Ÿæˆ"),
            ("generate", conv.thread_id_generate, "ç”¨ä¾‹ç”Ÿæˆ"),
        ]
        
        for idx, (phase, thread_id, phase_name) in enumerate(phase_configs, 1):
            if not thread_id:
                continue
            
            # è·å–è¯¥é˜¶æ®µçš„æ¶ˆæ¯
            phase_messages = await get_thread_history(thread_id)
            
            if phase_messages:
                # æ·»åŠ é˜¶æ®µåˆ†éš”ç¬¦ï¼ˆæ¨¡æ‹Ÿå®æ—¶æµçš„æ•ˆæœï¼‰
                divider = f"\n\n{'â”€' * 20} ğŸš€ **é˜¶æ®µ {idx}: {phase_name}** {'â”€' * 20}\n\n"
                
                # å°†åˆ†éš”ç¬¦æ·»åŠ åˆ°ç¬¬ä¸€æ¡ AI æ¶ˆæ¯çš„å¼€å¤´
                for msg in phase_messages:
                    if msg["role"] == "assistant" and msg.get("content"):
                        msg["content"] = divider + msg["content"]
                        break
                
                all_messages.extend(phase_messages)
        
        # 4. è·å–ä»»åŠ¡å†å²ï¼ˆä» TestSessionTask è¡¨è¯»å–ï¼‰
        task_records = db.query(TestSessionTask).filter(
            TestSessionTask.session_id == session_id
        ).order_by(TestSessionTask.phase, TestSessionTask.sort_order).all()
        
        task_history = {
            "analysis": [],
            "plan": [],
            "generate": [],
        }
        for task in task_records:
            task_history[task.phase].append({
                "id": task.id,
                "title": task.title,
                "scope": task.scope,
                "status": task.status,
                "progress": task.progress,
                "result": task.result,
            })
        
        logger.info(f"[HistoryService] è·å–æµ‹è¯•å†å²: session={session_id}, "
                   f"tasks={sum(len(t) for t in task_history.values())}, "
                   f"phases_completed={[p for p, v in phases_status.items() if v['completed']]}")
        
        # æ£€æŸ¥å½“å‰çŠ¶æ€
        current_phase = conv.current_phase
        status = conv.status
        
        return {
            "messages": all_messages,
            "phases": phases_status,
            "current_phase": current_phase,
            "status": status,
            "task_history": task_history,
        }
        
    except Exception as e:
        logger.error(f"[HistoryService] è·å–æµ‹è¯•ä¼šè¯å†å²å¤±è´¥: {e}")
        return {"messages": [], "phases": {}, "task_history": {}}


def _parse_multimodal_content(content) -> tuple:
    """è§£æå¤šæ¨¡æ€ contentï¼Œæå–æ–‡æœ¬å’Œé™„ä»¶
    
    Args:
        content: HumanMessage çš„ contentï¼Œå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–æ•°ç»„
        
    Returns:
        (text_content, attachments) å…ƒç»„
    """
    if isinstance(content, str):
        return content, []
    
    if not isinstance(content, list):
        return str(content), []
    
    text_parts = []
    attachments = []
    
    for item in content:
        if not isinstance(item, dict):
            continue
            
        item_type = item.get("type", "")
        
        if item_type == "text":
            text = item.get("text", "")
            # è¿‡æ»¤æ‰é™„ä»¶å¼•ç”¨æ–‡æœ¬ï¼ˆä»¥ "[é™„ä»¶:" å¼€å¤´ï¼‰
            if text and not text.strip().startswith("[é™„ä»¶:"):
                text_parts.append(text)
        
        elif item_type == "image_url":
            image_url = item.get("image_url", {})
            url = image_url.get("url", "") if isinstance(image_url, dict) else ""
            if url:
                # ä» URL æå–æ–‡ä»¶å
                filename = url.split("/")[-1].split("?")[0] if "/" in url else "image"
                attachments.append({
                    "file_id": "",  # å†å²è®°å½•ä¸­æ²¡æœ‰ file_id
                    "url": url,
                    "type": "image",
                    "filename": filename,
                    "content_type": "image/png"  # é»˜è®¤
                })
    
    return "".join(text_parts), attachments


def _extract_text_from_content(content) -> str:
    """ä» content ä¸­æå–çº¯æ–‡æœ¬
    
    Args:
        content: æ¶ˆæ¯çš„ contentï¼Œå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–æ•°ç»„
        
    Returns:
        æ–‡æœ¬å†…å®¹
    """
    if isinstance(content, str):
        return content
    
    if not isinstance(content, list):
        return str(content)
    
    text_parts = []
    for item in content:
        if isinstance(item, dict) and item.get("type") == "text":
            text_parts.append(item.get("text", ""))
    
    return "".join(text_parts)


def _extract_user_question(content) -> str:
    """ä» content ä¸­æå–ç”¨æˆ·çš„åŸå§‹é—®é¢˜ï¼ˆè¿‡æ»¤æ‰è§£æåçš„æ–‡æ¡£å†…å®¹ï¼‰
    
    Args:
        content: HumanMessage çš„ contentï¼Œå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–æ•°ç»„
        
    Returns:
        ç”¨æˆ·çš„åŸå§‹é—®é¢˜æ–‡æœ¬
    """
    if isinstance(content, str):
        return content
    
    if not isinstance(content, list):
        return str(content)
    
    text_parts = []
    for item in content:
        if not isinstance(item, dict):
            continue
        
        if item.get("type") == "text":
            text = item.get("text", "")
            # è¿‡æ»¤æ‰æ–‡æ¡£å†…å®¹ï¼ˆä»¥ "--- æ–‡æ¡£:" å¼€å¤´çš„å—ï¼‰
            if text and not text.strip().startswith("--- æ–‡æ¡£:") and not text.strip().startswith("\n\n--- æ–‡æ¡£:"):
                # ä¹Ÿè¿‡æ»¤æ‰é™„ä»¶å¼•ç”¨å’Œæ–‡æ¡£è§£æå¤±è´¥çš„æç¤º
                if not text.strip().startswith("[é™„ä»¶:") and not text.strip().startswith("[æ–‡æ¡£"):
                    text_parts.append(text)
    
    return "".join(text_parts).strip()


async def get_raw_messages(thread_id: str) -> list:
    """è·å–åŸå§‹çš„ LangChain æ¶ˆæ¯å¯¹è±¡åˆ—è¡¨
    
    Args:
        thread_id: ä¼šè¯ ID
        
    Returns:
        åŸå§‹æ¶ˆæ¯å¯¹è±¡åˆ—è¡¨
    """
    try:
        async with AsyncSqliteSaver.from_conn_string("llm_checkpoints.db") as memory:
            config = get_agent_config(thread_id)
            checkpoint_tuple = await memory.aget_tuple(config)
            
            if not checkpoint_tuple or not checkpoint_tuple.checkpoint:
                return []
            
            return checkpoint_tuple.checkpoint.get("channel_values", {}).get("messages", [])
    except Exception as e:
        logger.error(f"[HistoryService] è·å–åŸå§‹æ¶ˆæ¯å¤±è´¥: {e}")
        return []


async def replace_assistant_response(thread_id: str, user_msg_index: int, new_messages: list) -> bool:
    """æ›¿æ¢æŒ‡å®šç”¨æˆ·æ¶ˆæ¯å¯¹åº”çš„ AI å›å¤
    
    Args:
        thread_id: ä¼šè¯ ID
        user_msg_index: ç”¨æˆ·æ¶ˆæ¯åœ¨"ç”¨æˆ·æ¶ˆæ¯åˆ—è¡¨"ä¸­çš„ç´¢å¼•ï¼ˆä»0å¼€å§‹ï¼‰
        new_messages: æ–°çš„ AI å›å¤æ¶ˆæ¯åˆ—è¡¨ï¼ˆLangChain æ¶ˆæ¯å¯¹è±¡ï¼‰
        
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    try:
        async with AsyncSqliteSaver.from_conn_string("llm_checkpoints.db") as memory:
            config = get_agent_config(thread_id)
            checkpoint_tuple = await memory.aget_tuple(config)
            
            if not checkpoint_tuple or not checkpoint_tuple.checkpoint:
                logger.warning(f"[HistoryService] ä¼šè¯ä¸å­˜åœ¨: thread_id={thread_id}")
                return False
            
            checkpoint = checkpoint_tuple.checkpoint
            messages = checkpoint.get("channel_values", {}).get("messages", [])
            if not messages:
                return False
            
            # æ‰¾åˆ°ç¬¬ N ä¸ª human æ¶ˆæ¯çš„å®é™…ä½ç½®
            human_count = 0
            target_human_idx = -1
            for i, msg in enumerate(messages):
                if getattr(msg, "type", None) == "human":
                    if human_count == user_msg_index:
                        target_human_idx = i
                        break
                    human_count += 1
            
            if target_human_idx == -1:
                logger.warning(f"[HistoryService] æ‰¾ä¸åˆ°ç”¨æˆ·æ¶ˆæ¯ index={user_msg_index}")
                return False
            
            # æ‰¾åˆ°ä¸‹ä¸€ä¸ª human æ¶ˆæ¯çš„ä½ç½®ï¼ˆæˆ–æ¶ˆæ¯æœ«å°¾ï¼‰
            next_human_idx = len(messages)
            for i in range(target_human_idx + 1, len(messages)):
                if getattr(messages[i], "type", None) == "human":
                    next_human_idx = i
                    break
            
            # æ„å»ºæ–°çš„æ¶ˆæ¯åˆ—è¡¨ï¼šå‰é¢ + ç›®æ ‡ç”¨æˆ·æ¶ˆæ¯ + æ–°å›å¤ + åç»­æ¶ˆæ¯
            new_message_list = (
                messages[:target_human_idx + 1] +  # åŒ…å«ç›®æ ‡ç”¨æˆ·æ¶ˆæ¯
                new_messages +                      # æ–°çš„ AI å›å¤
                messages[next_human_idx:]           # åç»­æ¶ˆæ¯ï¼ˆä»ä¸‹ä¸€ä¸ªç”¨æˆ·æ¶ˆæ¯å¼€å§‹ï¼‰
            )
            
            checkpoint["channel_values"]["messages"] = new_message_list
            
            await memory.aput(
                checkpoint_tuple.config,
                checkpoint,
                checkpoint_tuple.metadata,
                {}
            )
            
            logger.info(f"[HistoryService] æ›¿æ¢ AI å›å¤æˆåŠŸ: thread_id={thread_id}, user_msg_index={user_msg_index}, åŸæ¶ˆæ¯æ•°={len(messages)}, æ–°æ¶ˆæ¯æ•°={len(new_message_list)}")
            return True
            
    except Exception as e:
        logger.error(f"[HistoryService] æ›¿æ¢ AI å›å¤å¤±è´¥: {e}")
        return False


def _extract_ai_summary(content: str, max_length: int = 300) -> str:
    """ä» AI å›å¤ä¸­æå–çº¯æ­£æ–‡æ‘˜è¦ï¼ˆå»é™¤ think å—å’Œå·¥å…·å ä½ç¬¦ï¼‰
    
    Args:
        content: AI å›å¤åŸå§‹å†…å®¹
        max_length: æœ€å¤§å­—ç¬¦æ•°
        
    Returns:
        æå–çš„æ­£æ–‡æ‘˜è¦
    """
    import re
    
    if not content:
        return ""
    
    # ç§»é™¤ <think>...</think> å—
    text = re.sub(r'<think>.*?</think>', '', content, flags=re.DOTALL)
    # ç§»é™¤æœªé—­åˆçš„ <think> å—ï¼ˆæµå¼è¾“å‡ºä¸­æ–­çš„æƒ…å†µï¼‰
    text = re.sub(r'<think>.*', '', text, flags=re.DOTALL)
    # ç§»é™¤å·¥å…·å ä½ç¬¦ <!--TOOL:xxx:n-->
    text = re.sub(r'<!--TOOL:[^>]+-->', '', text)
    # æ¸…ç†å¤šä½™ç©ºç™½
    text = re.sub(r'\n{3,}', '\n\n', text).strip()
    
    if len(text) > max_length:
        text = text[:max_length] + "..."
    
    return text


async def generate_conversation_title(db: Session, thread_id: str) -> str:
    """æ ¹æ®ä¼šè¯å†å²ç”Ÿæˆæ ‡é¢˜
    
    Args:
        db: æ•°æ®åº“ä¼šè¯
        thread_id: ä¼šè¯ ID
        
    Returns:
        ç”Ÿæˆçš„æ ‡é¢˜ï¼ˆ10å­—ä»¥å†…ï¼‰
    """
    try:
        # 1. è·å–å†å²è®°å½•
        history = await get_thread_history(thread_id)
        if not history:
            return "æ–°å¯¹è¯"
            
        # 2. æ‰¾åˆ°ç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
        first_user_msg = next((m for m in history if m["role"] == "user"), None)
        if not first_user_msg:
            return "æ–°å¯¹è¯"
            
        question = first_user_msg["content"]
        
        # 3. æå– AI å›å¤çš„æ­£æ–‡æ‘˜è¦ï¼ˆå»é™¤ think/toolï¼Œæœ€å¤š 300 å­—ï¼‰
        first_ai_msg = next((m for m in history if m["role"] == "assistant"), None)
        ai_summary = _extract_ai_summary(first_ai_msg["content"], 300) if first_ai_msg else ""
        
        # 4. è°ƒç”¨è½»é‡ LLM ç”Ÿæˆæ ‡é¢˜
        llm = get_lite_task_llm(db)
        
        if ai_summary:
            prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹å¯¹è¯å†…å®¹ï¼Œç”Ÿæˆä¸€ä¸ªç®€çŸ­çš„ä¼šè¯æ ‡é¢˜ï¼ˆ5ä¸ªå­—ä»¥ä¸Šï¼Œä¸è¶…è¿‡15ä¸ªå­—ï¼‰ã€‚
åªè¿”å›æ ‡é¢˜å†…å®¹ï¼Œä¸è¦åŒ…å«å¼•å·æˆ–å…¶ä»–è¯´æ˜ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{question}

AIå›å¤æ‘˜è¦ï¼š{ai_summary}

æ ‡é¢˜ï¼š"""
        else:
            prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹ç”¨æˆ·é—®é¢˜ï¼Œç”Ÿæˆä¸€ä¸ªç®€çŸ­çš„ä¼šè¯æ ‡é¢˜ï¼ˆ5ä¸ªå­—ä»¥ä¸Šï¼Œä¸è¶…è¿‡15ä¸ªå­—ï¼‰ã€‚
åªè¿”å›æ ‡é¢˜å†…å®¹ï¼Œä¸è¦åŒ…å«å¼•å·æˆ–å…¶ä»–è¯´æ˜ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{question}
æ ‡é¢˜ï¼š"""
        
        response = await llm.ainvoke(prompt)
        title = response.content.strip().replace('"', '').replace('ã€Š', '').replace('ã€‹', '')
        
        # å†æ¬¡æˆªæ–­ä»¥é˜²ä¸‡ä¸€
        title = title[:20]
        
        # 4. æ›´æ–°æ•°æ®åº“
        try:
            conv = db.query(Conversation).filter(Conversation.id == thread_id).first()
            if conv:
                conv.title = title
                db.commit()
        except Exception as e:
            logger.error(f"[HistoryService] ä¿å­˜æ ‡é¢˜åˆ°æ•°æ®åº“å¤±è´¥: {e}")
            
        return title
        
    except Exception as e:
        logger.error(f"[HistoryService] ç”Ÿæˆæ ‡é¢˜å¤±è´¥: {e}")
        return "æ–°å¯¹è¯"


async def generate_testing_title(
    db: Session, 
    thread_id: str, 
    requirement_id: str, 
    requirement_name: str
) -> str:
    """ä¸ºæ™ºèƒ½æµ‹è¯•ä¼šè¯ç”Ÿæˆæ ‡é¢˜
    
    åŸºäºéœ€æ±‚ä¿¡æ¯ç”Ÿæˆæ ‡é¢˜ï¼Œä¸éœ€è¦ç­‰å¾…å¯¹è¯å®Œæˆã€‚
    
    Args:
        db: æ•°æ®åº“ä¼šè¯
        thread_id: ä¼šè¯ ID
        requirement_id: éœ€æ±‚ç¼–å·
        requirement_name: éœ€æ±‚æ ‡é¢˜
        
    Returns:
        ç”Ÿæˆçš„æ ‡é¢˜ï¼ˆ15å­—ä»¥å†…ï¼‰
    """
    try:
        # è°ƒç”¨è½»é‡ LLM ç”Ÿæˆæ ‡é¢˜
        llm = get_lite_task_llm(db)
        
        prompt = f"""è¯·ä¸ºä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå¯¹è¯ç”Ÿæˆä¸€ä¸ªç®€çŸ­çš„æ ‡é¢˜ï¼ˆä¸è¶…è¿‡15ä¸ªå­—ï¼‰ã€‚
è¿™æ˜¯ä¸€ä¸ªæ ¹æ®éœ€æ±‚ç”Ÿæˆæµ‹è¯•æ–¹æ¡ˆå’Œç”¨ä¾‹çš„å¯¹è¯ã€‚

éœ€æ±‚ç¼–å·ï¼š{requirement_id}
éœ€æ±‚æ ‡é¢˜ï¼š{requirement_name}

è¦æ±‚ï¼š
- æ ‡é¢˜åº”è¯¥ç®€æ´æ˜äº†ï¼Œèƒ½ä½“ç°éœ€æ±‚çš„æ ¸å¿ƒå†…å®¹
- ä¸è¶…è¿‡15ä¸ªå­—
- åªè¿”å›æ ‡é¢˜å†…å®¹ï¼Œä¸è¦åŒ…å«å¼•å·æˆ–å…¶ä»–è¯´æ˜

æ ‡é¢˜ï¼š"""
        
        response = await llm.ainvoke(prompt)
        title = response.content.strip().replace('"', '').replace('ã€Š', '').replace('ã€‹', '')
        
        # æˆªæ–­ä»¥é˜²ä¸‡ä¸€
        title = title[:20]
        
        # æ›´æ–°æ•°æ®åº“
        try:
            conv = db.query(Conversation).filter(Conversation.id == thread_id).first()
            if conv:
                conv.title = title
                db.commit()
        except Exception as e:
            logger.error(f"[HistoryService] ä¿å­˜æµ‹è¯•ä¼šè¯æ ‡é¢˜åˆ°æ•°æ®åº“å¤±è´¥: {e}")
            
        return title
        
    except Exception as e:
        logger.error(f"[HistoryService] ç”Ÿæˆæµ‹è¯•ä¼šè¯æ ‡é¢˜å¤±è´¥: {e}")
        # é™çº§ï¼šä½¿ç”¨éœ€æ±‚åç§°çš„å‰15ä¸ªå­—ç¬¦
        return requirement_name[:15] if requirement_name else "æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ"


async def save_error_to_history(
    thread_id: str,
    question: str,
    partial_response: str,
    error_message: str,
) -> bool:
    """å°†æŠ¥é”™ä¿¡æ¯ä¿å­˜åˆ°å¯¹è¯å†å²
    
    å½“å¯¹è¯ä¸­é€”æŠ¥é”™æ—¶ï¼Œå°†ç”¨æˆ·é—®é¢˜ã€å·²ç”Ÿæˆçš„éƒ¨åˆ†å›å¤å’Œé”™è¯¯ä¿¡æ¯ä¸€èµ·ä¿å­˜ï¼Œ
    ä»¥ä¾¿æ¢å¤å†å²å¯¹è¯æ—¶èƒ½çœ‹åˆ°æŠ¥é”™çš„é‚£æ¬¡å¯¹è¯ã€‚
    
    Args:
        thread_id: ä¼šè¯ ID
        question: ç”¨æˆ·é—®é¢˜
        partial_response: å·²ç”Ÿæˆçš„éƒ¨åˆ† AI å›å¤
        error_message: é”™è¯¯æ¶ˆæ¯
        
    Returns:
        æ˜¯å¦æˆåŠŸä¿å­˜
    """
    try:
        async with AsyncSqliteSaver.from_conn_string("llm_checkpoints.db") as memory:
            config = get_agent_config(thread_id)
            checkpoint_tuple = await memory.aget_tuple(config)
            
            # æ„é€ é”™è¯¯æç¤ºå†…å®¹ï¼ˆä¸å‰ç«¯æ˜¾ç¤ºä¸€è‡´ï¼Œä¸æ³„éœ²å †æ ˆï¼‰
            if partial_response:
                error_content = f"{partial_response}\n\n---\n\nå¯¹è¯ä¸­æ–­ï¼š{error_message}"
            else:
                error_content = f"å¯¹è¯å¤±è´¥ï¼š{error_message}"
            
            # æ„é€ æ¶ˆæ¯
            user_msg = HumanMessage(content=question)
            ai_msg = AIMessage(content=error_content)
            
            if checkpoint_tuple and checkpoint_tuple.checkpoint:
                # å·²æœ‰ checkpointï¼Œåªè¿½åŠ  AI é”™è¯¯å“åº”ï¼ˆç”¨æˆ·æ¶ˆæ¯å·²ç”± Agent ä¿å­˜ï¼‰
                checkpoint = checkpoint_tuple.checkpoint
                messages = checkpoint.get("channel_values", {}).get("messages", [])
                # ä¸å†è¿½åŠ  user_msgï¼Œå› ä¸º Agent æ‰§è¡Œæ—¶å·²ç»ä¿å­˜äº†ç”¨æˆ·æ¶ˆæ¯
                messages.append(ai_msg)
                checkpoint["channel_values"]["messages"] = messages
                
                await memory.aput(
                    checkpoint_tuple.config,
                    checkpoint,
                    checkpoint_tuple.metadata,
                    {}
                )
            else:
                # æ–°ä¼šè¯ï¼Œåˆ›å»º checkpoint
                new_checkpoint = {
                    "v": 1,
                    "id": str(uuid.uuid4()),
                    "ts": str(uuid.uuid4()),
                    "channel_values": {
                        "messages": [user_msg, ai_msg]
                    },
                    "channel_versions": {},
                    "versions_seen": {},
                }
                await memory.aput(
                    config,
                    new_checkpoint,
                    {"source": "error_recovery", "step": 0},
                    {}
                )
            
            logger.info(f"[HistoryService] ä¿å­˜é”™è¯¯åˆ°å†å²æˆåŠŸ: thread_id={thread_id}, partial_len={len(partial_response)}")
            return True
            
    except Exception as e:
        logger.error(f"[HistoryService] ä¿å­˜é”™è¯¯åˆ°å†å²å¤±è´¥: {e}")
        return False
