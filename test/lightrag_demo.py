"""
LightRAG æœ€å°æ¶æ„æµ‹è¯•è„šæœ¬

åŠŸèƒ½ï¼š
1. æ‰‹åŠ¨é€‰æ‹© PDF/TXT/MD æ–‡æ¡£
2. å¯¼å…¥åˆ° LightRAG (å‘é‡åº“ + Neo4j å›¾è°±)
3. æ˜¾ç¤ºå¯¼å…¥è¿›åº¦
4. æ§åˆ¶å°å¯¹è¯æµ‹è¯•

ä½¿ç”¨æ–¹æ³•ï¼š
    pip install lightrag-hku[neo4j] pymupdf
    python test/lightrag_demo.py
"""

import os
import sys
import asyncio
import logging
from pathlib import Path
from typing import Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° path
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# ============== æ—¥å¿—é…ç½® ==============
# è®¾ç½® LightRAG è¯¦ç»†æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s | %(name)s | %(levelname)s | %(message)s',
    datefmt='%H:%M:%S'
)
# LightRAG æ ¸å¿ƒæ—¥å¿—
logging.getLogger("lightrag").setLevel(logging.DEBUG)
# HTTP è¯·æ±‚æ—¥å¿— (å¯ä»¥çœ‹åˆ° embedding è°ƒç”¨)
logging.getLogger("httpx").setLevel(logging.DEBUG)
logging.getLogger("openai").setLevel(logging.DEBUG)
# é™ä½å…¶ä»–å™ªéŸ³
logging.getLogger("httpcore").setLevel(logging.WARNING)
logging.getLogger("neo4j").setLevel(logging.INFO)

# ============== é…ç½® (ç¡¬ç¼–ç ï¼Œæµ‹è¯•é˜¶æ®µ) ==============

# Neo4j é…ç½® (å¤ç”¨ç°æœ‰)
NEO4J_URI = "neo4j+s://c6010ae0.databases.neo4j.io"
NEO4J_USERNAME = "neo4j"
NEO4J_PASSWORD = "GMaCBUonUoHZCYcqa8mBho_FAjVBnykTlEdgpMKLdZU"

# LightRAG é…ç½®
LIGHTRAG_WORKING_DIR = str(PROJECT_ROOT / "test" / "lightrag_data")
LIGHTRAG_WORKSPACE = "opdoc"  # Neo4j æ•°æ®éš”ç¦»å‰ç¼€

# LLM é…ç½® (å¯¹è¯æ¨¡å‹)
LLM_API_KEY = "sk-z7HUcbUoz6yVKBnEPrMiXnrljTmzmRNpHBL224MqgFoOxoux"  # æ›¿æ¢ä¸ºä½ çš„ API Key
LLM_BASE_URL = "https://88996.cloud/v1"  # æˆ–ä½ çš„ç½‘å…³åœ°å€
LLM_MODEL = "gemini-2.5-flash"

# Embedding é…ç½® (å‘é‡æ¨¡å‹) - å•ç‹¬é…ç½®
EMBEDDING_API_KEY = "sk-vxyvdnryevgolxatlsqilklzpiyfadxpkkqpvsagrgvuzavi"  # Embedding æœåŠ¡çš„ API Key
EMBEDDING_BASE_URL = "https://api.siliconflow.cn/v1"  # Embedding æœåŠ¡åœ°å€
EMBEDDING_MODEL = "Qwen/Qwen3-Embedding-8B"
EMBEDDING_DIM = 4096  # å‘é‡ç»´åº¦ï¼Œéœ€ä¸æ¨¡å‹åŒ¹é…

# ============== å·¥å…·å‡½æ•° ==============

def extract_text_from_pdf(pdf_path: str) -> str:
    """ä» PDF æå–æ–‡æœ¬"""
    try:
        import fitz  # pymupdf
        doc = fitz.open(pdf_path)
        text = ""
        for page_num, page in enumerate(doc):
            text += f"\n--- Page {page_num + 1} ---\n"
            text += page.get_text()
        doc.close()
        return text
    except ImportError:
        print("âš ï¸  pymupdf æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install pymupdf")
        return ""

def extract_text_from_file(file_path: str) -> str:
    """ä»æ–‡ä»¶æå–æ–‡æœ¬"""
    path = Path(file_path)
    suffix = path.suffix.lower()
    
    if suffix == ".pdf":
        return extract_text_from_pdf(file_path)
    elif suffix in [".txt", ".md", ".markdown"]:
        with open(file_path, "r", encoding="utf-8") as f:
            return f.read()
    else:
        print(f"âš ï¸  ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {suffix}")
        return ""

def select_file() -> Optional[str]:
    """é€‰æ‹©æ–‡ä»¶ (æ”¯æŒæ‹–æ‹½æˆ–è¾“å…¥è·¯å¾„)"""
    print("\n" + "=" * 50)
    print("ğŸ“‚ è¯·è¾“å…¥æ–‡æ¡£è·¯å¾„ (æ”¯æŒ PDF/TXT/MD)")
    print("   æˆ–å°†æ–‡ä»¶æ‹–æ‹½åˆ°æ­¤çª—å£")
    print("=" * 50)
    
    file_path = input("\næ–‡ä»¶è·¯å¾„: ").strip().strip('"').strip("'")
    
    if not file_path:
        return None
    
    if not Path(file_path).exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return None
    
    return file_path

# ============== LightRAG å°è£… ==============

class LightRAGDemo:
    def __init__(self):
        self.rag = None
        self._setup_env()
    
    def _setup_env(self):
        """è®¾ç½®ç¯å¢ƒå˜é‡"""
        os.environ["NEO4J_URI"] = NEO4J_URI
        os.environ["NEO4J_USERNAME"] = NEO4J_USERNAME
        os.environ["NEO4J_PASSWORD"] = NEO4J_PASSWORD
        os.environ["OPENAI_API_KEY"] = LLM_API_KEY
        
        # ç¡®ä¿å·¥ä½œç›®å½•å­˜åœ¨
        os.makedirs(LIGHTRAG_WORKING_DIR, exist_ok=True)
    
    async def initialize(self):
        """åˆå§‹åŒ– LightRAG"""
        print("\nğŸš€ æ­£åœ¨åˆå§‹åŒ– LightRAG...")
        
        try:
            from lightrag import LightRAG
            from lightrag.llm.openai import openai_complete_if_cache, openai_embed
            from lightrag.utils import EmbeddingFunc
            from lightrag.kg.shared_storage import initialize_pipeline_status
            import numpy as np
            
            # è‡ªå®šä¹‰ LLM å‡½æ•°
            async def llm_func(prompt, system_prompt=None, history_messages=[], **kwargs):
                return await openai_complete_if_cache(
                    model=LLM_MODEL,
                    prompt=prompt,
                    system_prompt=system_prompt,
                    history_messages=history_messages,
                    api_key=LLM_API_KEY,
                    base_url=LLM_BASE_URL,
                    **kwargs
                )
            
            # è‡ªå®šä¹‰ Embedding å‡½æ•° (å¸¦ phase è¿›åº¦è·Ÿè¸ª)
            self.embedding_stats = {
                "total_texts": 0,
                "phase": "",           # å½“å‰ phase
                "phase_total": 0,      # å½“å‰ phase æ€»æ•°
                "phase_done": 0,       # å½“å‰ phase å·²å®Œæˆ
                "start_time": None,
            }
            
            async def embedding_func(texts: list[str]) -> np.ndarray:
                import time
                stats = self.embedding_stats
                if stats["start_time"] is None:
                    stats["start_time"] = time.time()
                
                stats["total_texts"] += len(texts)
                stats["phase_done"] += len(texts)
                
                # æ˜¾ç¤ºè¿›åº¦
                if stats["phase"] and stats["phase_total"] > 0:
                    progress = min(100, stats["phase_done"] / stats["phase_total"] * 100)
                    bar = "â–ˆ" * int(progress / 5) + "â–‘" * (20 - int(progress / 5))
                    print(f"\r   ğŸ“Š {stats['phase']} [{bar}] {stats['phase_done']}/{stats['phase_total']} ({progress:.0f}%)", end="", flush=True)
                else:
                    print(f"\r   ğŸ“Š Embedding: {stats['total_texts']} æ¡", end="", flush=True)
                
                result = await openai_embed(
                    texts,
                    model=EMBEDDING_MODEL,
                    api_key=EMBEDDING_API_KEY,
                    base_url=EMBEDDING_BASE_URL,
                )
                return result
            
            # åˆ›å»º LightRAG å®ä¾‹
            self.rag = LightRAG(
                working_dir=LIGHTRAG_WORKING_DIR,
                llm_model_func=llm_func,
                embedding_func=EmbeddingFunc(
                    embedding_dim=EMBEDDING_DIM,
                    max_token_size=8192,
                    func=embedding_func,
                ),
                # å­˜å‚¨é…ç½®
                graph_storage="Neo4JStorage",           # å¤ç”¨ Neo4j
                vector_storage="NanoVectorDBStorage",   # é»˜è®¤è½»é‡å‘é‡
                kv_storage="JsonKVStorage",
                doc_status_storage="JsonDocStatusStorage",

                # éš”ç¦»é…ç½®
                workspace=LIGHTRAG_WORKSPACE,
                # æ€§èƒ½ä¼˜åŒ–
                chunk_token_size=1200,                  # åˆ†å—å¤§å° (é»˜è®¤1200)
                chunk_overlap_token_size=100,           # é‡å å¤§å° (é»˜è®¤100)
                embedding_batch_num=8,                 # æ¯æ‰¹ embedding æ•°é‡
                embedding_func_max_async=1,             # embedding å¹¶å‘æ•° - ç¡…åŸºæµåŠ¨rpmé™åˆ¶æ¯”è¾ƒç‹ ï¼Œé…ç½®ä¸º2éƒ½ä¼šå¯¼è‡´rate limit
                llm_model_max_async=6,                  # LLM å¹¶å‘æ•°
                # è¯­è¨€é…ç½®
                addon_params={
                    "language": "Chinese",              # è¾“å‡ºä¸­æ–‡
                },
            )
            
            # åˆå§‹åŒ–å­˜å‚¨
            await self.rag.initialize_storages()
            await initialize_pipeline_status()
            
            print("âœ… LightRAG åˆå§‹åŒ–æˆåŠŸ!")
            print(f"   ğŸ“ å·¥ä½œç›®å½•: {LIGHTRAG_WORKING_DIR}")
            print(f"   ğŸ—„ï¸  Neo4j: {NEO4J_URI}")
            print(f"   ğŸ·ï¸  Workspace: {LIGHTRAG_WORKSPACE}")
            print()
            print("   âš™ï¸  æ€§èƒ½é…ç½®:")
            print(f"      - chunk_token_size: {self.rag.chunk_token_size}")
            print(f"      - embedding_batch_num: {self.rag.embedding_batch_num}")
            print(f"      - embedding_func_max_async: {self.rag.embedding_func_max_async}")
            print(f"      - llm_model_max_async: {self.rag.llm_model_max_async}")
            print()
            print("   ğŸŒ è¯­è¨€é…ç½®:")
            print(f"      - language: {self.rag.addon_params.get('language', 'English')}")
            
        except ImportError as e:
            print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
            print("   è¯·è¿è¡Œ: pip install lightrag-hku[neo4j]")
            sys.exit(1)
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def insert_document(self, file_path: str):
        """å¯¼å…¥æ–‡æ¡£"""
        if not self.rag:
            print("âŒ LightRAG æœªåˆå§‹åŒ–")
            return False
        
        file_name = Path(file_path).name
        print(f"\nğŸ“„ æ­£åœ¨å¤„ç†æ–‡æ¡£: {file_name}")
        
        # 1. æå–æ–‡æœ¬
        print("   [1/3] æå–æ–‡æœ¬...")
        text = extract_text_from_file(file_path)
        if not text:
            print("âŒ æ–‡æœ¬æå–å¤±è´¥")
            return False
        
        print(f"   âœ“ æå–å®Œæˆï¼Œå…± {len(text)} å­—ç¬¦")
        
        # é‡ç½® embedding ç»Ÿè®¡
        self.embedding_stats = {
            "total_texts": 0,
            "phase": "",
            "phase_total": 0,
            "phase_done": 0,
            "start_time": None,
        }
        
        # 2. æ·»åŠ æ–‡æ¡£æ ‡è¯†å¹¶å¯¼å…¥
        doc_content = f"[æ–‡æ¡£åç§°: {file_name}]\n\n{text}"
        print("   [2/3] æ­£åœ¨ç´¢å¼• (å®ä½“æå– + å‘é‡åŒ–)...")
        
        import time
        import re
        from lightrag.kg.shared_storage import get_namespace_data, get_pipeline_status_lock
        
        start_time = time.time()
        stats = self.embedding_stats
        
        # å¯åŠ¨åå°è¿›åº¦ç›‘å¬ä»»åŠ¡
        async def monitor_progress():
            try:
                pipeline_status = await get_namespace_data("pipeline_status")
                pipeline_status_lock = get_pipeline_status_lock()
                last_message = ""
                while True:
                    await asyncio.sleep(0.3)
                    async with pipeline_status_lock:
                        current_message = pipeline_status.get("latest_message", "")
                        if current_message and current_message != last_message:
                            elapsed = time.time() - start_time
                            
                            # è§£æ phase ä¿¡æ¯å¹¶æ›´æ–°ç»Ÿè®¡
                            # æ ¼å¼: "Phase 1: Processing 45 entities from doc-xxx"
                            # æ ¼å¼: "Phase 2: Processing 32 relations from doc-xxx"
                            match = re.search(r'Phase (\d+): Processing (\d+) (entities|relations)', current_message)
                            if match:
                                phase_num = match.group(1)
                                total = int(match.group(2))
                                phase_type = match.group(3)
                                stats["phase"] = f"Phase {phase_num} ({phase_type})"
                                stats["phase_total"] = total
                                stats["phase_done"] = 0  # é‡ç½®è¿›åº¦
                                print(f"\n   ğŸ“¡ [{elapsed:.0f}s] {current_message}", flush=True)
                            elif "Completed merging" in current_message:
                                # å®Œæˆ merging é˜¶æ®µ
                                stats["phase"] = ""
                                stats["phase_total"] = 0
                                print(f"\n   âœ… [{elapsed:.0f}s] {current_message}", flush=True)
                            else:
                                print(f"\n   ğŸ“¡ [{elapsed:.0f}s] {current_message}", flush=True)
                            
                            last_message = current_message
            except asyncio.CancelledError:
                pass
        
        monitor_task = asyncio.create_task(monitor_progress())
        
        try:
            # ä¼ å…¥ file_paths å‚æ•°ï¼Œä½¿ LightRAG ç”Ÿæˆæ­£ç¡®çš„ reference_id
            await self.rag.ainsert(doc_content, file_paths=[file_path])
            monitor_task.cancel()
            try:
                await monitor_task
            except asyncio.CancelledError:
                pass
            elapsed = time.time() - start_time
            print()  # æ¢è¡Œ
            print(f"   âœ“ ç´¢å¼•å®Œæˆ! å®é™… embedding: {self.embedding_stats['total_texts']} æ¡, è€—æ—¶ {elapsed:.1f}s")
        except Exception as e:
            monitor_task.cancel()
            print(f"\n   âŒ ç´¢å¼•å¤±è´¥: {e}")
            return False
        
        # 3. å®Œæˆ
        print("   [3/3] âœ… æ–‡æ¡£å¯¼å…¥æˆåŠŸ!")
        return True
    
    async def query(self, question: str, only_context: bool = False) -> str:
        """
        æŸ¥è¯¢é—®ç­”
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            only_context: å¦‚æœä¸º Trueï¼Œåªè¿”å›æ£€ç´¢ä¸Šä¸‹æ–‡ï¼Œä¸è§¦å‘ AI å›ç­”
        """
        if not self.rag:
            return "âŒ LightRAG æœªåˆå§‹åŒ–"
        
        try:
            from lightrag import QueryParam
            result = await self.rag.aquery(
                question,
                param=QueryParam(
                    mode="hybrid",
                    only_need_context=only_context,  # åªè¿”å›ä¸Šä¸‹æ–‡
                )
            )
            return result
        except Exception as e:
            return f"âŒ æŸ¥è¯¢å¤±è´¥: {e}"
    
    async def close(self):
        """å…³é—­è¿æ¥"""
        if self.rag:
            try:
                await self.rag.finalize_storages()
                print("\nğŸ”Œ å·²å…³é—­ LightRAG è¿æ¥")
            except:
                pass

# ============== ä¸»ç¨‹åº ==============

async def main():
    print("\n" + "=" * 60)
    print("   ğŸ”® LightRAG æœ€å°æ¶æ„æµ‹è¯• - æ“ä½œæ–‡æ¡£é—®ç­”")
    print("=" * 60)
    
    demo = LightRAGDemo()
    
    try:
        # åˆå§‹åŒ–
        await demo.initialize()
        
        # ä¸»å¾ªç¯
        while True:
            print("\n" + "-" * 40)
            print("è¯·é€‰æ‹©æ“ä½œ:")
            print("  1. å¯¼å…¥æ–‡æ¡£")
            print("  2. å¼€å§‹å¯¹è¯ (AI å›ç­”)")
            print("  3. æ£€ç´¢æ¨¡å¼ (åªè¿”å›ä¸Šä¸‹æ–‡)")
            print("  4. é€€å‡º")
            print("-" * 40)
            
            choice = input("è¯·è¾“å…¥é€‰é¡¹ (1/2/3/4): ").strip()
            
            if choice == "1":
                # å¯¼å…¥æ–‡æ¡£
                file_path = select_file()
                if file_path:
                    await demo.insert_document(file_path)
                    
            elif choice == "2":
                # å¯¹è¯æ¨¡å¼ - AI å›ç­”
                print("\nğŸ’¬ è¿›å…¥å¯¹è¯æ¨¡å¼ (è¾“å…¥ 'exit' é€€å‡º)")
                print("-" * 40)
                
                while True:
                    question = input("\nğŸ™‹ ä½ : ").strip()
                    
                    if question.lower() in ["exit", "quit", "q", "é€€å‡º"]:
                        print("ğŸ‘‹ é€€å‡ºå¯¹è¯æ¨¡å¼")
                        break
                    
                    if not question:
                        continue
                    
                    print("\nğŸ¤– AI: ", end="", flush=True)
                    answer = await demo.query(question, only_context=False)
                    print(answer)
            
            elif choice == "3":
                # æ£€ç´¢æ¨¡å¼ - åªè¿”å›ä¸Šä¸‹æ–‡
                print("\nğŸ” è¿›å…¥æ£€ç´¢æ¨¡å¼ (åªè¿”å›ä¸Šä¸‹æ–‡ï¼Œä¸è§¦å‘ AI å›ç­”)")
                print("   è¿”å›å†…å®¹åŒ…æ‹¬: å®ä½“æè¿° + å…³ç³»æè¿° + æ–‡æ¡£å—")
                print("-" * 40)
                
                while True:
                    question = input("\nğŸ” æ£€ç´¢: ").strip()
                    
                    if question.lower() in ["exit", "quit", "q", "é€€å‡º"]:
                        print("ğŸ‘‹ é€€å‡ºæ£€ç´¢æ¨¡å¼")
                        break
                    
                    if not question:
                        continue
                    
                    print("\nğŸ“„ æ£€ç´¢ç»“æœ:")
                    print("=" * 50)
                    context = await demo.query(question, only_context=True)
                    print(context)
                    print("=" * 50)
                    
            elif choice == "4":
                print("\nğŸ‘‹ å†è§!")
                break
            else:
                print("âŒ æ— æ•ˆé€‰é¡¹ï¼Œè¯·é‡æ–°è¾“å…¥")
    
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
    finally:
        await demo.close()

if __name__ == "__main__":
    asyncio.run(main())
